#!/usr/bin/env python
# Copy data between different machines running jive5a(b(c))
import socket, time, sys, math, copy, itertools, pydoc, re, os, datetime, string, traceback, subprocess

## Current version
version="$Id$"

## Bastard Python devs. "datetime.timedelta" objects
## only acquired ".total_seconds()" in 2.7
def total_seconds(td):
    if hasattr(td, 'total_seconds'):
        return td.total_seconds()
    else:
        return  (td.microseconds + (td.seconds + td.days * 24 * 3600) * 10**6) / 10**6

## Standardized date/time format
def timestampNow():
    return datetime.datetime.now().strftime("%Y-%b-%dT%Hh%Mm%Ss")
    #return datetime.datetime.isoformat( datetime.datetime.now() )

########################################
# Attempt to find the external IP
# address of this machine. On multi-homed
# machines it will return None
#
# This method is used in order to be able
# to set a default external ip address
# in case someone tries to do a network
# copy *into* the local machine (i.e. the
# machine m5copy is running on); in this
# case, the DST::controlip == 127.0.0.1 
# and telling a remote jive5ab to connect
# to that address isn't going to work
# very well, is it?
##########################################
def get_local_ext_ip(unique=True):
    # I've looked all over the 'net but there is
    # no portable Python way to get the
    # available interface addresses, other than
    # executing ifconfig ... (bah!)
    rxIf   = re.compile(r"^(?P<if>[^:]+):?\s+(Link|flags)")
    rxInet = re.compile(r"^\s*inet\s+((addr)?\s*:?\s*)(?P<inet>\S+)")

    # Note: this should never *break* m5copy
    try:
        tmp    = set()
        curIF  = None

        ifconfig = subprocess.Popen(["/sbin/ifconfig", "-a"], stdout=subprocess.PIPE)
        for line in ifconfig.communicate()[0].split('\n'):
            mo = rxIf.match(line)
            if mo:
                curIF = mo.group('if')
                continue
            mo = rxInet.match(line)
            if mo:
                # inspect the inet address; we're definitely skipping
                # 127.0.0.1 and multicast addresses
                inet = mo.group('inet')
                msb  = int( inet.split('.')[0] )
                if not (inet=="127.0.0.1" or (msb>=224 and msb<=239)):
                    tmp.add( inet )
        # tmp is the set of all IP addresses for this machine that are
        # not loopback or multicast
        if unique:
            return tmp.pop() if len(tmp)==1 else None
        else:
            return tmp
    except:
        return None


############################
## Support for 'enums'
##
## X = enum("AAP", "NOOT")
##
## var = X.AAP
##  ...
## if var == X.AAP:
##     ...
############################

class enum(object):
    def __init__(self, *seq):
        self.enums = seq
        for e in self.enums:
            setattr(self, e, e)

    # you can iterate over the enum to find out all defined values
    def __iter__(self):
        class enumiter(object):
            def __init__(self,enuminst):
                self.iterable = enuminst
                self.iter     = iter(enuminst.enums)
            def next(self):
                return getattr(self.iterable, self.iter.next())
        return enumiter(self)

    def __getitem__(self, idx):
        if idx in self.enums:
            return idx
        raise IndexError,"{0} does not exist".format(idx)

## take a list of (pattern, replacement) tuples and run them 
## over the string to produce the final edited string
subber   = lambda acc, (pat, repl): re.sub(pat, repl, acc)
sub      = lambda txt, lst: reduce(subber, lst, txt)

## expands string "1:10,13,20:22" into [1,2,3,4,5,6,7,8,9,10,13,20,21,22]
##   and "5:2" into [5,4,3,2]
##
## Supports arbitrary increments
##    1:10:2 => [1,3,5,7,9]
## Support arithmetic:
##  "2*10:3*10,12-2:12+2"
##  All expressions will be converted to int after evaluating
def expand_string_range(s, rchar=":"):
    rxNum = re.compile(r"^\d+$")
    rxRng = re.compile(r"^(?P<s>[-\d\.+*/%()]+)"+rchar+"(?P<e>[-\d\.+*/%()]+)(:(?P<step>[-+]?\d+))?$")
    def count_from_to(s,e,step):
        while abs(s-e)>=abs(step):
            #print "s:{0} e:{1} diff:{2}".format(s, e, abs(s-e))
            yield s
            s = s + step
        if abs(s-e)<=abs(step):
            yield s
        raise StopIteration
    def mkcounter(item):
        mo = rxRng.match(item)
        if mo:
            # start, end may be expressions
            (s,e) = (int(eval(mo.group('s'))), int(eval(mo.group('e'))))
            defstep = 1 if (s<e) else -1
            step    = mo.group('step')
            step    = int(step) if step else defstep
            # Test if we actually *can* count from start -> end using step:
            # e.g.:    1 -> 10, step -1 isn't going to end very well is it?
            #         -1 -> -10, step 1         ,,           ,,
            # Step size "0" is ONLY allowed if start==end!
            # Also assure ourselves that the step direction and counting
            # direction are identical
            if (not step and (s-e)) or (((e-s) * step )<0):
                raise RuntimeError,"cannot count from {0} to {1} with step {2}".format(s, e, step)
            return count_from_to(s, e, step)
        else:
            mo = rxNum.match(str(eval(item)))
            if not mo:
                raise ValueError, "{0} is not a number! (It's a free man!)".format(item)
            # 'item' may be an expression!
            item = int(eval(item))
            # Note: seems superfluous to return a counter for 1 number but now
            # we have a list of iterables which can easily be transformed into
            # one list via itertools.chain() (see below)
            return count_from_to(item, item, 1)
    return list(itertools.chain(*[mkcounter(x) for x in s.split(",")]))


# given a number + unit, return number between 1.0 and scale +prefix+unit
#  ie.  1024000 "Byte" => "1000 kByte"
def sciprint(num, unit, scale=1000, fmt=".2f"):
    if num<1.0:
        prefixes = ["m", "u", "n", "f", "p", ""] 
        fn       = lambda (n, p), pfx: (n*scale, pfx) if n<1.0 and (n*scale!=n) else (n, p)
    else:
        prefixes = ["k", "M", "G", "T", "P", "E"]
        fn       = lambda (n, p), pfx: (n/scale, pfx) if n>scale else (n, p)
    (n, p) = reduce(fn, prefixes, (float(num), ""))
    return "{0:{n_fmt}} {1}{2}".format(n, p, unit, n_fmt=fmt)



def progress_print(x):
    sys.stdout.write(x)
    sys.stdout.flush()

## A function returning a nice progress update including a bar + percentage, a la scp(1)
def progress(cur, s, e, sz):
    frac = (float(cur - s)/float(e - s)) if e!=s else 0
    pos  = int( frac * sz )
    if pos==0:
        pos = 1
    return "Progress |" + "="*(pos-1) + ">" + " "*(sz-pos)+"| {0:6.2f}%".format(frac*100)


class Progress(object):
    def __init__(self, size):
        self.now       = datetime.datetime.now
        self.size      = size
        self.lastTime  = self.now()
        self.lastCount = 0
        self.maxLen    = 0

    def __call__(self, current, start, end):
        now   = self.now()
        count = (current - start)
        dt    = total_seconds(now - self.lastTime)
        speed = 0.0
        if dt>0:
            speed = (count - self.lastCount) / dt
        txt = progress(current, start, end, self.size)+" "+sciprint(speed, "byte/s", 1024)+" "*10+"\r"
        self.maxLen = max(self.maxLen, len(txt))
        progress_print( txt )
        self.lastTime  = now
        self.lastCount = count

    def say(self, txt):
        self.maxLen = max(self.maxLen, len(txt))
        progress_print( txt + " "*(self.maxLen - len(txt))+"\r" )

    def done(self):
        progress_print(" "*85+"\r")

class DummyProgress(object):
    def __init__(self):
        pass
    def __call__(self, current, start, end):
        pass
    def say(self, txt):
        pass
    def done(self):
        pass

### Sometimes you need a random sequence of 'n' alphanumerical characters
rndChars    = string.letters + string.digits
random_word = lambda n: ''.join(map(lambda x: rndChars[ord(x)%len(rndChars)], os.urandom(n)))
        


############################################################################
## Defaults for the transfer: standard TCP protocol, Mark5 control,data port
############################################################################

mtu            = 1500
ipd            = 0
timeOut        = None
realtime       = False
nthread        = 1
queries        = False
verbose        = True
protocol       = "tcp"
dataport       = 2630
duplicates     = False
controlport    = 2620
uri_type       = enum("SRC", "DST")
media_type     = enum("FILE", "DISK", "VBS", "IN", "MEM")
bank_type      = enum("A", "B")
uniqSuffix     = lambda scannum: ".scan." + str(scannum)
allowOverwrite = False  # this is a dangerous one ...


def usage():
    elp = get_local_ext_ip()
    def_dataip= "DST::host (destination control ip/host)" if elp is None else elp
    pydoc.pager( 
"""
Usage: {progname} [options] SRC DST

Copy VLBI data from SRC to DST. Both SRC and or DST may be located on remote
machines; the default is to address data on the local machine. There is a
possibility to force the data over a different network in case there exists a
different/faster network between the SRC and DST machines than the control
network. Please find examples at the end of the documentation.

Options:

    -h        print this message and exit
    -v        print current version and exit
    -q        be quiet, do not display progress (default: {def_verbose})
    -a        allow duplicate scan names on a disk pack to be 
              automatically renamed to <scan>.<scannumber> (default: {def_allow})
    -udt      use UDT as protocol (default: {def_proto})
    -rt       allow real time transfer. Only supported on "in://" and
              "mem://" SRC transfers. If set, it will enable the
              (unreliable) e-VLBI protocol "UDPs" - UDP with sequence number.
    -p <port> use this port number for data channel (default: {def_data_port})
    -m <mtu>  use this MTU (default: {def_mtu})
              Note: only used when using UDT or real-time protocol!
    -r <rate> limit transmit data rate to <rate> bits per second.
              (default: unlimited - as fast as it will go).
              For your convenience you may use the suffixes 'kMG',
              metric thousands ("x1000"), not binary thousands.
              Note: only effective when using UDT!
    -t <#sec> set socket timeout to <#sec> seconds. Note that the
              program may use different time out values yet; m5copy knows
              that some commands generally take longer to complete than
              others. m5copy uses the maximum time out value of the
              internally specified value and the command line supplied
              value, if any.
    -n <num>  use <num> parallel chunk transfers when doing
              flexbuff => flexbuff transfers (default: {def_nthread})

    SRC, DST: uri-like VLBI data locations. Supported formats:

    mk5://[host][:port][:dataip][/BANK|VSN]/<scan id>
        This addresses a scan on a Mark5 disk pack.

        For SRC uri the <scan id> may be a name, number or a comma-
            separated list of numbers or range of numbers: 1-10,13,14.
            The name may contain the wildcard characters '*' or '?' -
            all scan names matching the pattern will be transferred.
            For scan number ranges, the range is inclusive the last number.

        For DST uri the <scan id> will ONLY be interpreted as name;
            we cannot force the scan id number - it depends on what
            is already recorded on the target disk pack. If the name
            happens to be numeric, your scan will be called that.

        The BANK may be provided as "A" or "B" (case insensitive) but is
        optional. If nothing is specified the current active bank on the
        Mark5 will be used.
        
        If something is specified for BANK|VSN and it's not "A" or "B", the
        string will be interpreted as VSN. An error will happen if the given
        VSN cannot be found/switched to on the indicated Mark5.

    file://[host][:port][:dataip]/path/to/(file|dir/)
        Addresses a file or directory on disk (trailing slash means directory).

        In SRC file URIs wildcards '*' and '?' are allowed, provided you're
        running m5copy on the machine itself. Remote wildcards are NOT
        supported. 
        
        SRC file URIs may never address a directory. DST file URIs _MUST_
        name a directory IF the source consists of multiple files/scans.

    in://[host][:port]/[amount[kMGs]]
        Addresses the I/O board in the Mark5, to which the formatter or
        DBBC is directly connected to. This is a SRC URI only!

        With this SRC you can take data directly from the telescope and save
        it somewhere: on the local Mark5 or, if the network and the disks
        on the remote system are fast enough too, on a remote system.

        'amount' is the amount of data to capture. If 'amount' is not
        specified, the transfer will run until you cancel the transfer by
        pressing ^C. 
        
        'amount' given without unit means "number of bytes". With unit
        suffix of 'k', 'M' or 'G', the program will attempt to capture as
        close to the amount of bytes, kB, MB or GB as specified. The
        'thousands' here are binary thousands, thus powers of 1024.

        'amount' with unit 's' (for seconds) will capture data for that
        amount of seconds. Again,this is only an approximation.

        When using this SRC, it is assumed that _someone else_ has correctly
        set up the Mark5 mode and play rate or clock setting (Mark5B).

    mem://[host][:port]/[amount[kMGs]]
        Addresses the memory buffer inside jive5ab. If jive5ab is started
        with the '-b' option on the Mark5, recorded data will be mirrored in
        a memory buffer inside jive5ab. This one is also SRC only URI.

        With this SRC you can take data directly from that buffer and save
        it somewhere: on the local Mark5 or, if the network and the disks
        on the remote system are fast enough too, on a remote system.

        The explanation of the 'amount' parameter is identical to that under
        the 'in://' explanation.

        It should be pointed out that with this SRC, if there is no
        recording going on, no data will flow. You can start this transfer
        and it will start the data flow as soon as someone else turns on
        recording. However, if you specified the duration in seconds, the
        time will count from the moment of invocation, irrespective of if
        there is data flowing.

        Just to be absolutely clear about it:

        IF JIVE5AB IS NOT IN BUFFERING MODE, NO DATA WIL BE TRANSFERRED BY
        THIS TRANSFER. EVAR.

        If this statement doesn't mean anything to you but still sounds like
        you want to use this form of transport, contact the author for an
        explanation.

    vbs://[host][:port][:dataip]/[recording]
        Addresses a vlbi_streamer (vbs) recording on a FlexBuff.
        VBS -> VBS transfers are an 'rsync' operation rather than a
        copy. Therefore some restrictions apply for those transfers.

        In SRC vbs URIs the recording MUST be specified and wildcard
        expansion is only allowed on the local machine.

        On SRC vbs URIs, the "[:dataip]" is not supported. The recording
        name may only be set if the data source is 'mk5://' or 'file://'
        because in VBS -> VBS transfers the name of the recording is
        transferred implicitly; on account of this essentially being an
        rsync operation.

ALL KINDS OF IPv4 ADDRESSES

    The "host" and "port" fields in the URI's are for the CONTROL channel:
    m5copy will send the VSI/S formatted commands to this address.
    
    The "dataip" override field is only allowed in the DST uri. It is
    optional and will override the destination ip/host address (the DST
    control IP) where the data will be sent to.
    
    Typically this option is used to force data over a faster network
    between the SRC and DST machines, bypassing the CONTROL network.

    Note: setting the data port is done using a separate option on the
    command line.

    Defaults are:
        host        localhost/127.0.0.1
        port        {def_ctrl_port}
        dataip      {def_data_ip}


EXAMPLES

    On a Mark5, copy scan 1-10 from local disk => local file ("disk2file").
    Each scan will end up in "/data/<scanname>.m5a":

        m5copy mk5:///1-10 file:///data/

    Extract scan 200 and rename it:

        m5copy mk5:///200 file:///data/scan200.m5a

    You can force the scans of a specific experiment to be read from a
    specific VSN:

        m5copy mk5:///cmva-007/ek035* file:///data/

    Or from a specific bank:

        m5copy mk5:///B/*ef* file:///data/

    Do a file server => Mark5 copy, forcing data to to a specific VSN,
    "file2net2disk". Each file will become a new scan on the disk pack with
    the name of the file with its extension removed:

        m5copy file:///data/gr* mk5://10.88.0.50/jod+017/

    Do a remote disk2file; i.e. trigger a local disk2file on a Mark5 from
    e.g. your control computer ("remote disk2file"):

        m5copy mk5://10.88.0.50/1-10 file://10.88.0.50/data/

    Push data from a specified VSN loaded in a remote Mark5 to a directory
    on a remote file server. Assume the Mark5 and file server's "control"
    IPv4 addresses are on the 10.88.0.* subnet and there is a high-speed
    data link between the Mark5 and the file server over a different IPv4
    subnet, 192.42.120.*. The file server has IPv4 addresses
    10.88.0.22 (control) and 192.42.120.110 (fat data pipe).

    Using this form of m5copy ensures the data will go over the fast
    192.42.120.* network whilst the control commands are sent over the
    normal network, "disk2net2file". The SRC jive5ab will be told to open
    the data connection to "dataip=192.42.120.110":

        m5copy mk5://10.88.0.50/ file://10.88.0.22::192.42.120.110/data/


    Copy 512MB of data directly from the I/O board to a remote file:

        m5copy in://effelsberg.ip.address/512M file://io11.mpg-bonn.de/data/

""".format(progname=sys.argv[0], def_proto=protocol, def_data_port=dataport, \
           def_ctrl_port=controlport, def_mtu=mtu, def_verbose=verbose, \
           def_nthread=nthread, def_allow=duplicates, def_data_ip=def_dataip) )


# One-liner to split a list of things into two lists, one satisfying the predicate, the other not
partition = lambda p, l: reduce(lambda (y,n), x: (y+[x], n) if p(x) else (y, n+[x]), l, ([], []))

######
# Utils
######


# will always resolve to IPv4 address such that 
# user can mix names/ip-addresses and the system will
# still compare them equal (provided they resolve to
# the same IPv4 address, of course)
def resolve_ip(host_or_ip):
    # the socket.getaddrinfo returns a list of 5-element tuples
    # we only want the IPv4 address out of the 5th element ("(ip, port)")
    # and we default to the first returned entry for the host
    try:
        return socket.getaddrinfo(host_or_ip, 0, socket.AF_INET, socket.SOCK_STREAM)[0][4][0]
    except:
        print "Failed to resolve the following name '{0}'".format(host_or_ip)
        raise 


rxBytenumOffset  = re.compile(r"^(?P<sign>\+)?(?P<amount>[0-9]+)(?P<scale>[kMG])?$")
rxBytenumRate    = re.compile(r"^(?P<sign>\+)?(?P<amount>[0-9]+(\.[0-9]*)?|\.[0-9]+)(?P<scale>[kMG])?$")
scaleTableBinary = {'k': 1024, 'M':1024*1024, 'G': 1024*1024*1024, '':1, None:1}
scaleTableMetric = {'k': 1000, 'M':1000000, 'G': 1000000000, '':1, None:1}

def procByte(bn, tp, rxBytenum, scaleTable):
    mo = rxBytenum.match(bn)
    if not mo:
        raise RuntimeError, "{0}: invalid byte number".format(bn)
    # passed the regex test, now we can do stuff
    amount = tp(mo.group('amount'))
    scale  = mo.group('scale')
    sign   = mo.group('sign')
    if scale:
        amount *= scaleTable[scale]
    return (sign if sign else '')+str(amount)


class URI(object):
    ## define a static method - the URI factory
    @staticmethod
    def makeURI(src_or_dst, media):
        if src_or_dst==uri_type.SRC:
            return SourceURI(media, src_or_dst)
        elif src_or_dst==uri_type.DST:
            return DestURI(media, src_or_dst)
        else:
            raise ValueError, "Cannot create neither a source or dest URI type"

    def __init__(self, media, src_or_dst):
        self.direction   = src_or_dst
        # who to talk to
        self.controlIP   = None
        self.controlPort = None

        # will be "media_type.FILE" or "media_type.DISK" or "media_type.VBS"
        if not media in media_type:
            raise RuntimeError, "Unrecognized media type '{0}'".format(media)
        self.mediaType   = media

        # contents of path will depend on 
        # media type
        self.path        = None

    def get_direction(self):
        return self.direction

    def __str__(self):
        # do we have these attributes?
        haveSE  = (hasattr(self,'startByte') and hasattr(self, 'endByte'))
        # are any of these not None?
        needSE  = haveSE and (self.startByte or self.endByte)
        # then we possibly need to tag them on
        seBytes = (":"+ (self.startByte if self.startByte else "") + ":" + (self.endByte if self.endByte else "")) if needSE else ''
        return "{0}::{1} [{2}:{3}{4}] {5}{6}{7}".format(self.direction, self.mediaType, self.controlIP, self.controlPort, \
                                                (":"+(self.dataIP if self.dataIP else "<controlIP>") if hasattr(self,'dataIP') else ""), \
                                                ((self.bank+"/" if self.bank else "") if hasattr(self, 'bank') else ""), self.path, \
                                                seBytes)

    def parseStartEndByte(self, sb, eb):
        # if any of the start/end bytes are set and we
        # do not have one of the attributes ... 
        if (sb or eb) and not (hasattr(self, 'startByte') and hasattr(self, 'endByte')):
            raise RuntimeError, "{0} does not support configuring start and/or end byte number".format(str(self))

        if sb: 
            self.startByte = procByte(sb, int, rxBytenumOffset, scaleTableBinary)
        
        if eb:
            self.endByte = procByte(eb, int, rxBytenumOffset, scaleTableBinary)

class SourceURI(URI):
    def __init__(self, media, src_or_dst):
        super(SourceURI, self).__init__(media, src_or_dst)

        # Some URIs support start, end byte
        # These will be *functions* which both will be 
        # passed the current start and end byte of the scan
        # being processed such they can do the appropriate offset
        # magic (eg negative numbers work from the end etc),
        # but always only on data source(s)
        self.startByte   = None
        self.endByte     = None

        if self.mediaType==media_type.DISK:
            self.bank    = None
            self.VSN     = None



class DestURI(URI):
    def __init__(self, media, src_or_dst):
        super(DestURI, self).__init__(media, src_or_dst)
        self.dataIP      = None

        if self.mediaType==media_type.DISK:
            self.bank    = None
            self.VSN     = None


rxDisk    = re.compile(r"^mk5:")
rxFile    = re.compile(r"^file:")
rxVBS     = re.compile(r"^vbs:")
rxINorMEM = re.compile("^(?P<type>in|mem):")

## For URI parsing we must know if we're parsing source or destination
## URI's. 'src_or_dst' is an 'enum' (see below)
def parseURI(uri, src_or_dst):
    if rxDisk.match(uri):
        return parseDisk(uri, src_or_dst)
    elif rxFile.match(uri):
        return parseFile(uri, src_or_dst )
    elif rxVBS.match(uri):
        return parseVBS(uri, src_or_dst )
    elif rxINorMEM.match(uri):
        return parseINorMEM(uri, src_or_dst )
    else:
        raise ValueError, "Unrecognized URI '{0}'".format(uri)


## Not loosely modelled after jive5ab's OPTARG macro, honestly .... ;-)
def OPTARG(lst, n, default=None):
    try:
        return lst[n] if len(lst[n]) else default
    except IndexError:
        return default


# supported:
#  mk5://[host][:port][:dataip]/[BANK|VSN/]<scanname:scanids>[:[<start>][:<end>|+<amount>]]
# So, before the first "/" is all kind of host/ip/port crap.
# note that "[:dataip]" is only supported on source URIs
def parseDisk(uri_org, src_or_dst):
    uri = re.sub("^mk5:", "", uri_org)
    rv = URI.makeURI(src_or_dst, media_type.DISK)

    # the host/port/dataip is between the leading double slash and the third
    # slash
    mo = re.match(r"^//([^/]*)/", uri)
    if not mo:
        raise RuntimeError, "{0}: invalid - does not match //.../".format(uri_org)
    hoststuff = mo.group(1)

    # now that we have matched the hoststuff out of it, we can take it out
    # of the URI
    path = re.sub(r"^//[^/]*/", "", uri)

    # any slashes remaining in the path means that a bank/vsn was passed
    slashed = path.split("/")
    if len(slashed)>2:
        raise RuntimeError, "{0}: invalid - too many slashes in bank/scan part".format(uri_org)

    # the last part is always the scanid/number
    # On a source disk, we MUST have a scan name, on DST it *may* be a scan name
    b, p = (None, None)
    if len(slashed)==2:
        (b, p) = slashed
    else:
        p = path

    # Did anyone mention start/end byte?
    p_split = p.split(':')
    rv.path = p_split[0]  # path is always the first bit

    if rv.direction==uri_type.SRC:
        if not rv.path:
            raise RuntimeError, "{0}: source URI MUST have a scan name/id".format(uri_org)

    # if there's a leading part, it's the bank/vsn
    if b:
        b = b.upper()
        if not b in bank_type:
            # must be VSN then
            if hasattr(rv, 'VSN'):
                rv.VSN = b
            else:
                raise RuntimeError, "{0}: media type {1} does not support setting VSN to {2}".format(uri_org, rv.mediaType, b)
        else:
            if hasattr(rv, 'bank'):
                rv.bank = b
            else:
                raise RuntimeError, "{0}: media type {1} does not support setting bank to {2}".format(uri_org, rv.mediaType, b)

    # Now parse the host/port stuff
    colonized = hoststuff.split(':')

    # Length check - at most three entries
    if len(colonized)>3:
        raise RuntimeError, "{0}: invalid 'host:port:dataip' part".format(uri_org)

    # Because we have the ":"'s separating the entries we only need to
    # verify if they exist at all
    rv.controlIP   = resolve_ip(OPTARG(colonized, 0, "localhost"))
    rv.controlPort = OPTARG(colonized, 1, controlport)
    if rv.controlPort:
        rv.controlPort = int(rv.controlPort)

    # Only dst-type URI's parse the data ip;
    # so we only set the value if the URI object _has_ that
    # attribute
    dataip = OPTARG(colonized, 2)
    if dataip:
        if hasattr(rv, 'dataIP'):
            rv.dataIP = resolve_ip(dataip)
        else:
            raise RuntimeError, "{0} does support setting of dataip ({1})".format(uri_org, src_or_dst)

    # Save the start/end byte number parsing for last such that the URI is filled in
    rv.parseStartEndByte( OPTARG(p_split, 1), OPTARG(p_split, 2) )
    return rv


## Supported:  (the leading "file:" has already been stripped)
##  file://[host][:port][:dataip]/path/to/file[:[<start>][:<end>|+<amount>]]
# note that "[:dataip]" is only supported on source URIs
def parseFile(uri_org, src_or_dst):
    uri = re.sub("^file:", "", uri_org)
    rv = URI.makeURI(src_or_dst, media_type.FILE)

    # the host/port/dataip is between the leading double slash and the third
    # slash
    mo = re.match(r"//([^/]*)/", uri)
    if not mo:
        raise RuntimeError, "{0}: invalid - does not match //.../".format(uri_org)
    hoststuff = mo.group(1)

    # now that we have matched the hoststuff out of it, we can take it out
    # of the URI
    p = re.sub(r"^//[^/]*", "", uri)

    # Did anyone mention start/end byte?
    p_split = p.split(':')
    rv.path = p_split[0]  # path is always the first bit - start/end is last (below)

    # On source file name we MUST have a filename
    if rv.direction==uri_type.SRC:
        if len(rv.path)<=1:
            raise RuntimeError, "{0}: source URI MUST have a file/path".format(uri_org)

    # Now parse the host/port stuff
    colonized = hoststuff.split(':')

    # Length check - at most three entries
    if len(colonized)>3:
        raise RuntimeError, "{0}: invalid 'host:port:dataip' part".format(uri_org)

    # Because we have the ":"'s separating the entries we only need to
    # verify if they exist at all
    rv.controlIP   = resolve_ip(OPTARG(colonized, 0, "localhost"))
    rv.controlPort = OPTARG(colonized, 1, controlport)
    if rv.controlPort:
        rv.controlPort = int(rv.controlPort)

    # Only source-type URI's parse the data ip;
    # so we only set the value if the URI object _has_ that
    # attribute
    dataip = OPTARG(colonized, 2)
    if dataip:
        if hasattr(rv, 'dataIP'):
            rv.dataIP = resolve_ip(dataip)
        else:
            raise RuntimeError, "{0} does not support setting of dataip ({1})".format(uri_org, src_or_dst)

    # Save the start/end byte number parsing for last such that the URI is filled in
    rv.parseStartEndByte( OPTARG(p_split, 1), OPTARG(p_split, 2) )
    return rv

# 'vbs' is a vlbi-streamer recording on a flexbuff
#  at the moment this one does *not* support 'slicing', i.e.
#  no start/end byte specification
#
#   vbs://[host][:port][:dataip]/recording
#
# note that "[:dataip]" is only supported on source URIs
def parseVBS(uri_org, src_or_dst):
    uri = re.sub("^vbs:", "", uri_org)
    rv = URI.makeURI(src_or_dst, media_type.VBS)

    # the host/port/dataip is between the leading double slash and the third
    # slash
    mo = re.match(r"//([^/]*)/", uri)
    if not mo:
        raise RuntimeError, "{0}: invalid - does not match //.../".format(uri_org)
    hoststuff = mo.group(1)

    # now that we have matched the hoststuff out of it, we can take it out
    # of the URI
    rv.path = re.sub(r"^//[^/]*/", "", uri)

    # Did anyone mention start/end byte?
    # we do parse them so we can yell if we find 'm :D
    if rv.path.count(':'):
        raise RuntimeError, "{0}: VBS recordings do not support start/end byte".format(uri_org)

    # On source vbs we MUST have a recording name
    if rv.direction==uri_type.SRC:
        if not rv.path:
            raise RuntimeError, "{0}: source URI MUST have a recording name".format(uri_org)

    if rv.path.count('/'):
        raise RuntimeError, "{0}: recording name may not contain slashes".format(uri_org)

    # Now parse the host/port stuff
    colonized = hoststuff.split(':')

    # Length check - at most three entries
    if len(colonized)>3:
        raise RuntimeError, "{0}: invalid 'host:port:dataip' part".format(uri_org)

    # Because we have the ":"'s separating the entries we only need to
    # verify if they exist at all
    rv.controlIP   = resolve_ip(OPTARG(colonized, 0, "localhost"))
    rv.controlPort = OPTARG(colonized, 1, controlport)
    if rv.controlPort:
        rv.controlPort = int(rv.controlPort)

    # Only source-type URI's parse the data ip;
    # so we only set the value if the URI object _has_ that
    # attribute
    dataip = OPTARG(colonized, 2)
    if dataip:
        if hasattr(rv, 'dataIP'):
            rv.dataIP = resolve_ip(dataip)
        else:
            raise RuntimeError, "{0} does not support setting of dataip ({1})".format(uri_org, src_or_dst)
    return rv

# 'in'  is the I/O board on Mark5A/B or C
#       this one is only supported as SRC uri
# 'mem' is reading data from the memory buffer
#       that is in jive5ab. We do not know
#       who put it there but we can read it!
#
# Because 'in' and 'mem' are basically identical in usage, we 
# parse them both in one method
#
#   (in|mem)://[host][:port][:dataip]/[[0-9]+[kMGs]]
#      the optional <number>[kMGs] is the amount of bytes (kMG) or
#      seconds (s) to transfer.
#      No unit implies 'just bytes'
#      If amount is in bytes, it will be an approximation; an attempt
#      will be made to retrieve the specified amount of bytes.
#      Default is to transfer indefinitely - can be stopped using ^C
rxAmount = re.compile(r"^(?P<amount>[0-9]+)(?P<unit>[kMGs])?$")
def parseINorMEM(uri_org, src_or_dst):
    if src_or_dst==uri_type.DST:
        raise RuntimeError, "{0} can only be used as SRC".format(uri_org)

    # Before removing the prefix, capture what it was!
    tp  = rxINorMEM.match(uri_org).group('type')
    uri = re.sub("^(in|mem):", "", uri_org)

    if tp=='in':
        rv  = URI.makeURI(src_or_dst, media_type.IN)
    elif tp=='mem':
        rv  = URI.makeURI(src_or_dst, media_type.MEM)

    # the host/port/dataip is between the leading double slash and the third
    # slash
    mo = re.match(r"//([^/]*)/", uri)
    if not mo:
        raise RuntimeError, "{0}: invalid - does not match //.../".format(uri_org)
    hoststuff = mo.group(1)

    # now that we have matched the hoststuff out of it, we can take it out
    # of the URI
    rv.path = re.sub(r"^//[^/]*/", "", uri)

    # Was there an amount of bytes/time specified?
    # (i.e. something left after taking out the initial part of the uri)
    # Note: at this point we only _verify_ that the 'path' matches.
    #       interpretation of the string will be done in the actual
    #       reading function
    if rv.path:
        if not rxAmount.match(rv.path):
            raise RuntimeError, "{0} - invalid amount of bytes/seconds specified".format(uri_org)

    # Now parse the host/port stuff
    colonized = hoststuff.split(':')

    # Length check - at most three entries
    if len(colonized)>3:
        raise RuntimeError, "{0}: invalid 'host:port:dataip' part".format(uri_org)

    # Because we have the ":"'s separating the entries we only need to
    # verify if they exist at all
    rv.controlIP   = resolve_ip(OPTARG(colonized, 0, "localhost"))
    rv.controlPort = OPTARG(colonized, 1, controlport)
    if rv.controlPort:
        rv.controlPort = int(rv.controlPort)

    # Only source-type URI's parse the data ip;
    # so we only set the value if the URI object _has_ that
    # attribute
    dataip = OPTARG(colonized, 2)
    if dataip:
        if hasattr(rv, 'dataIP'):
            rv.dataIP = resolve_ip(dataip)
        else:
            raise RuntimeError, "{0} does not support setting of dataip ({1})".format(uri_org, src_or_dst)
    return rv

###########################################
#              cornerturning support
###########################################


# Get nr of bits per sample out of the canonical mode
#  MKIVx_y-datarate-nchannel-bitpersample
#  VLBAx_y-datarate-nchannel-bitpersample
#  MARK5B-datarate-nchannel-bitpersample
rxMode = re.compile(r"^(((?P<mk4vlba>MKIV|VLBA)(?P<fanout1>\d)_(?P<fanout2>\d))|MARK5B)-(?P<rate>\d+)-\d+-(?P<bps>\d+)$", re.I)

# Split the VDIF params into an object with attributes
#   -vdif station:framesize[:[threads][:bpsample]]
def vdif_props(v):
    return reduce(lambda acc, ((at, fn), v): setattr(acc, at, fn(v)) or acc,
                  zip([("station", lambda x:x), ("framesize", int), ("threads", lambda x:x), ("bitspersample",int)], v.split(':')),
                  type('', (), {})())

# predefined modes => cornerturning setups
known_modes = {
        'MKIV1_2-256-8-2':  "8Ch2bit1to2_hv",
        'MKIV1_2-512-8-2':  "8Ch2bit1to2_hv",               # 32 tracks 1:2 fanout
        'MKIV1_2-512-16-2':  "32bitx2 + 8Ch2bit1to2_hv",    # 64 tracks 1:2 fanout
        'MKIV1_2-1024-16-2':  "32bitx2 + 8Ch2bit1to2_hv",    # 64 tracks 1:2 fanout
        'MKIV1_4-1024-16-2':"32bitx2 + 8Ch2bit1to4_hv",   # 64 tracks 1:4 fanout
        'MARK5B-1024-16-2': "swap_sign_mag + 16bitx2 + 8Ch2bit_hv",# 1024Mbps 16ch Mk5B
        'MARK5B-512-8-2':   "swap_sign_mag + 8Ch2bit_hv",          # 512Mbps  8ch  Mk5B
        'MARK5B-512-16-2':   "swap_sign_mag + 16bitx2 + 8Ch2bit_hv",# 512Mbps  16ch  Mk5B
}

do_corner   = False
mode        = None     # set from cmdline
vdif        = None     # set from cmdline
cornerturn  = None     # maybe set from cmdline

# Return list of commands + cornerturn recipe + vdif properties + output data format
# In case we do cornerturning, there is a format translation
# and as such, the output format of the data does not match
# the input format anymore

def ct_setup_commands(ct_cmd):
    # if cornerturn recipe not given, check if it is one of the known ones
    m          = mode.upper()
    ct_method  = (known_modes[m] if m in known_modes else None) if cornerturn is None else cornerturn
    if ct_method is None:
        raise RuntimeError, "No cornerturning known for {0}, specify '-ct ...' to run".format(mode)
    vd_props   = vdif_props(vdif)
    if not hasattr(vd_props, 'threads'):
        vd_props.threads = "0-15"
        print "cornerturn setup: no VDIF thread selection given, defaulting to {0}".format(vd_props.threads)

    # check fanout and bits-per-sample
    mo = rxMode.match(m)
    if not mo:
        raise RuntimeError, "Mode {0} is not like  <FORMAT>-<RATE>-<N_CHANNEL>-<BITSPERSAMPLE>".format(mode)
    # bits per channel is not necessarily == bits per sample; especially during fan-out
    # (with fan-out 1:2, there are twice as many bits for each sample as one would expect)
    # Mode (MarkIV|VLBA)<fanout1>_<fanout2>-....
    bps = int(mo.group('bps'))
    if mo.group('mk4vlba'):
        fo1 = int(mo.group('fanout1'))
        fo2 = int(mo.group('fanout2'))
    else:
        fo1 = fo2 = 1
    bpc = bps
    if fo2>fo1:
        bpc = bpc * (fo2 / fo1)
    # the output data format will always be legacy vdif, fully cornerturned (i.e. one channel per frame)
    oFmt = "VDIFL_{framesize}-{rate}-1-{bps}".format(framesize=vd_props.framesize, rate=mo.group('rate'), bps=bps)
    return  (
        [
            "mode={0}".format(mode),
            "{0}=bitspersample:{1}".format(ct_cmd, bps),
            "{0}=bitsperchannel:{1}".format(ct_cmd, bpc),
            "{0}=station:{1}".format(ct_cmd, vd_props.station),
            "{0}=vdifsize:{1}".format(ct_cmd, vd_props.framesize)
        ],
        ct_method, vd_props, oFmt )
    

###########################
# VSI-S command/reply stuff
###########################

def split_reply(reply):
    end_index = reply.rfind(';')
    if end_index != -1:
        reply = reply[:end_index]
    separator_index = reply.find('=')
    if separator_index == -1:
        separator_index = reply.find('?')
        if separator_index == -1:
            return [reply]

    return map(lambda x: x.strip(), [reply[0:separator_index]] + reply[separator_index+1:].split(':'))

## Facilitate communication with a Mark5
class Mark5(object):
    anyReturn = range(0,9)

    def __init__(self, address, port, timeout=5):
        self.timeout       = timeout
        self.connect_point = (address, port)
        self.socket        = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        self.socket.settimeout(self.timeout)
        try:
            self.socket.connect(self.connect_point)
        except:
            raise RuntimeError, "Failed to connect to {0}".format(self.connect_point)
   
    def get_type(self):
        return self.send_query("dts_id?")[2]

    def get_program(self):
        # this query should only return "0", not even "1"!
        return self.send_query("version?", [0])[2]

    def send_query(self, query, acceptable_codes=[0,1], timeout=None):
        if queries:
            print datetime.datetime.now(),self.connect_point,"Qry:",query

        # decide on the timeout to use
        toInternal = self.timeout if timeout is None else timeout
        toGlobal   = toInternal if timeOut is None else max(timeOut, toInternal)
        self.socket.settimeout(toGlobal)
        self.socket.send(query + "\n\r")
        orgreply = self.socket.recv(1024).strip()
        if queries:
            print datetime.datetime.now(),self.connect_point,"Reply:",orgreply
        reply = split_reply(orgreply)
        if not int(reply[1]) in acceptable_codes:
            raise RuntimeError, "Unacceptable return code {0} from query '{1}' - {2} [acceptable: {3}]".format(int(reply[1]), query, orgreply, acceptable_codes)
        return reply

    def location(self):
        return ":".join(map(str, self.connect_point))

    ## attempt to switch to bank 'bank' on the Mark5
    ## indicated by 'ctrl', assumed to be a 'Mark5' object
    def switch_bank(self, bank):
        bank    = bank.upper()
        actbank = self.send_query("bank_info?")[2].upper()
        if actbank!=bank:
            # issue the bank switch command
            reply = self.send_query("bank_set={0}".format(bank), [1])
            # wait for it to complete
            while True:
                time.sleep(1)
                reply = self.send_query("bank_set?", [0, 6])
                if reply[1]=="0":
                    break
            # verify it's a different bank than we started with
            if actbank==reply[2].upper():
                reply = self.send_query("error?")
                raise RuntimeError, "{0} could not switch to bank {1} [{2}]".format(self.location(), bank, ":".join(reply[3:]))
        return actbank

    # Attempt to switch to the bank containing the indicated VSN
    def switch_vsn(self, vsn):
        vsn = vsn.upper()

        # query which VSNs are currently loaded
        #  0          1   2       3         4       5
        #  !bank_set? 0 : [AB-] : <vsn>|- : [BA-] : <vsn>|- ;
        # Create a mapping of VSN => bank
        reply = self.send_query("bank_set?", [0])
        def proc_entry(acc, idx):
            # extract [<bank>, <vsn>]
            sel = reply[idx:idx+2]
            # if bank or vsn == '-': 
            #     'inactive bank' or 'no module loaded'
            if not "-" in sel:
                # Note: <vsn> is typically  <vsn>/<capacity>/<speed>
                acc[ sel[1].upper().split('/')[0] ] = sel[0].upper()
            return acc
        vsnbankmap = reduce(proc_entry, [2,4], {})
        if not vsn in vsnbankmap:
            raise RuntimeError, "{0} VSN {1} not found on this machine".format(self.location(), vsn)
        return self.switch_bank(vsnbankmap[vsn])

# default configuration for jive5ab for m5copy - separate it from direct
# Mark5 control class
class Jive5AB(Mark5):
    def __init__(self, address, port, timeout=5, runtime=None, bs="2M", modeless=True):
        super(Jive5AB, self).__init__(address, port, timeout)

        # do we have jive5* running on that connection?
        self.program = self.get_program()
        if not re.search("^jive5", self.program):
            raise RuntimeError, "{0}:{1} is not running a version of jive5a(b(c))".format(address, port)

        # Save the values of things that we're going to overwrite
        # Note: we set the ipd on both ends, even though it is
        #       only useful for the sender, and then only when UDT
        #       is used
        self.runtime    = copy.deepcopy(runtime)
        self.oldRuntime = None
        self.prevState  = {}

        # If we're going to create a new runtime there's no
        # point in saving the state anyway ....
        if self.runtime:
            self.oldRuntime = self.send_query("runtime?", [0])[2]
            self.send_query("runtime={0}:new".format(runtime), [0])
        else:
            self.save( ["net_protocol", "mtu", "ipd", "net_port"] )

        if modeless:
            self.send_query("mode=none", [0])
        self.send_query("net_protocol={0:s}:64M:{1}".format(protocol, bs), [0])
        self.send_query("mtu={0:d}".format(mtu), [0])
        self.send_query("ipd={0}ns".format(ipd))
        self.send_query("net_port={0:d}".format(dataport), [0])

    def save(self, cmdlist):
        self.prevState = dict(zip(cmdlist, map(lambda x: self.send_query(x+"?", [0]), cmdlist)))

    def restore(self):
        for (k,v) in self.prevState.iteritems():
            self.send_query(k+"="+":".join(v[2:]))
        if self.oldRuntime:
            self.send_query("runtime={0}:delete".format(self.runtime))
            self.send_query("runtime={0}".format(self.oldRuntime))


####################################################################
##
##  The model is:
##    a Source or Dest URI is passed to a DataSource or DataSink
##    the DataSource yields Scans to be transferred
##    Depending on the actual transfer a Source and Dest XFER
##    are created such that we can easily couple different
##    sources and destinations
##
####################################################################

class Scan(object):
    # no 'constructor', the only interesting bit is the interface
    # I know that in Python we could use 'duck typing' such that
    # the different objects only need to adhere to the same interface
    # but in my book that's called inheritance :D
    def name(self):
        raise RuntimeError,"Not implemented"

class DiskScan(Scan):
    def __init__(self, (num, name), **kwargs):
        self.scanId = (num, name)
        # set optianal extra attribute(s)
        self.__dict__.update( kwargs )

    def name( self ):
        return self.scanId[1]

class FileScan(Scan):
    def __init__(self, name):
        self.scanId = name

    def name( self ):
        return self.scanId


#####################################################################
##
## base classes for a xfer
##
##  DataSources must allow iteration over themselves; each iteration
##    step should yield the name of a transferrable unit. So even if
##    the URI addressed only a single unit, it should iterator over
##    a list of length one.
##
##  DataSinks:
## 
##    * must support computing an output name, given an input
##    name. Each data sink must be able to tell wether it allows
##    multiple names to be computed. E.g. the FileDest only allows
##    computation of multiple names IF it addresses a directory. If a 
##    specific name was given "/dir/file[.ext]" then obviously it
##    cannot compute >1 name. 
##    For the DiskDest this is similar; if an output scan name was
##    explicitly given, no more scan names can be computed
##
##    * must be able to tell wether they can compute multiple output
##    names such that the s/w can verify if the user has made an error
##    by specifying >1 input transferrable units and one specific output
##    name
##
##    * must be able to tell the dataIP to which the data must be sent
##
#####################################################################


class DataSource(Jive5AB):
    def __init__(self, src, runtime=None, modeless=True):
        self.source  = src
        super(DataSource, self).__init__(self.source.controlIP, self.source.controlPort, runtime=runtime, modeless=modeless)

    # must return a list of source paths
    def __iter__(self):
        raise RuntimeError, "Someone forgot to implement this one"
    def __next__(self):
        raise RuntimeError, "Someone forgot to implement this one"

    def cleanup(self):
        raise RuntimeError, "Someone forgot to implement this one"

    def startByte(self):
        return self.source.startByte

    def endByte(self):
        return self.source.endByte

    def location(self):
        return self.source.controlIP+"::"

class DataSink(Jive5AB):
    def __init__(self, dst, runtime=None):
        self.destination = dst
        super(DataSink, self).__init__(self.destination.controlIP, self.destination.controlPort, runtime=runtime)

    # Is the DataSink configured to support >1 output names?
    def multiple_outputs(self):
        raise RuntimeError, "Someone forgot to implement this one!"

    # Compute the output name of the given input
    def compute_outputname(self, input):
        raise RuntimeError, "Someone forgot to implement this one!"

    def cleanup(self):
        raise RuntimeError, "Someone forgot to implement this one"

    def dataIP(self):
        DST = self.destination
        return DST.dataIP if hasattr(DST, 'dataIP') and not DST.dataIP is None else DST.controlIP

    def location(self):
        return self.destination.controlIP+"::"

#########################################
##
##   Concrete derivatives of 
##        the base classes 
##
##########################################


#################### the sources ############################

## Mark5 disk pack as source
class DiskSource(DataSource):
    def __init__(self, location):
        super(DiskSource, self).__init__(location)

        SRC  = self.source

        # Select the requested bank or VSN, if one was given.
        # Note: bank and VSN are mutually exclusive at most one
        #       of them is actually set
        if SRC.bank:
            self.switch_bank(SRC.bank)
        if SRC.VSN:
            self.switch_vsn(SRC.VSN)

        # Look at the location - if it's made out of numbers, dashes and commas
        # it's a list of scan numbers, otherwise a scan name(s)
        rxNums = re.compile(r"^([0-9]+(-[0-9]+)?)(,([0-9]+(-[0-9]+)?))*$")

        filter_f = None
        if SRC.path=="*":
            # Short circuit for all scans
            filter_f = lambda x : True
        elif rxNums.match(SRC.path):
            scanids = set(expand_string_range(SRC.path, '-'))
            filter_f = lambda (num, name): num in scanids
        else:
            # replace "*" by ".*" and "?" by "."
            path     = sub(SRC.path, [("\.","\."), ("\*", ".*"), ("\+", "\+"), ("\?",".")])
            scanname = re.compile(r"^"+path+"$")
            filter_f = lambda (num, name): scanname.match(name)

        # Get the list of scans and immediately filter them
        nscan    = int(self.send_query("dir_info?", [0])[2])

        def get_scan(i):
            self.send_query("scan_set={0:d}".format(i), [0])
            r = self.send_query("scan_set?", [0])
            if int(r[2])!=i:
                raise RuntimeError, "Scan {0} failed to set".format(i)
            return (i, r[3])

        self.scanList = map(lambda x: DiskScan(x), \
                            filter(filter_f, map(get_scan, xrange(1, nscan+1))))

        # Check for duplicate names - if there are, either fix them or
        # fail with an error + hint as to what the user should do to fix
        # this
        names = set(map(lambda x: x.name(), self.scanList))
        if len(names)<len(self.scanList):
            # uh-oh. duplicate names!
            if not duplicates:
                raise RuntimeError, "Duplicate scan names found in your scan " + \
                                    "selection. Re-run with '-a' flag " + \
                                    "(see help) to have m5copy rename them " + \
                                    "on the output"
            # Step 1. figure out the names of the scans that have duplicates
            def countert(acc, scan):
                acc[scan.name()] = acc.get(scan.name(), 0) + 1
                return acc
            dupnames = map(lambda (k, v): k, filter(lambda (k,v): v>1, reduce(countert, self.scanList, {}).iteritems()))
            # Step 2. rename scans that have duplicate names
            def renamert( diskscan ):
                (num, name) = diskscan.scanId
                if name in dupnames:
                    return DiskScan( (num, name+uniqSuffix(num)), duplicate=True )
                else:
                    return diskscan
            self.scanList = map(renamert, self.scanList)

    # implement the DataSource part
    def __iter__(self):
        return iter(self.scanList)

    def __len__(self):
        return len(self.scanList)

    def location(self):
        SRC = self.source
        return super(DiskSource, self).location() + (SRC.bank+"/" if SRC.bank else (SRC.VSN+"/" if SRC.VSN else ""))

    def cleanup(self):
        self.restore()


class FileSource(DataSource):
    def __init__(self, location):
        # file transfers are done in a different runtime
        super(FileSource, self).__init__(location, runtime=random_word(8))

        # we cannot retrieve the list of files remotely
        # but only locally
        SRC  = self.source
        self.pathList         = [SRC.path]
        (self.dir, self.file) = os.path.split(SRC.path)

        # do we need to do wildcard processing?
        if '*' in SRC.path or '?' in SRC.path:
            if SRC.controlIP != '127.0.0.1':
                raise RuntimeError, "Unfortunately we do not support wildcards in file names on remote systems"
            # Check if path contains wildcards. Only allow those
            # in the file name part
            (dir, file) = os.path.split( SRC.path )
            if '*' in dir or '?' in dir:
                raise RuntimeError, "Wildcards not allowed in directory names"
            # we now know that the wildcard, if present, must reside in the file part
            # replace "*" by ".*" and "?" by "." in the file name
            # (also escape regex special chars)
            file     = sub(file, [("\.", "\."), ("\*", ".*"), ("\+", "\+"), ("\?",".")])
            filename = re.compile(r"^"+file+"$")
            # Only consider files located in 'dir'
            self.pathList = []
            for (root, dirs, files) in os.walk(dir):
                if root!=dir:
                    dirs = []
                    continue
                # use the reduce structure such that we do not _overwrite_ self.pathList
                # but append to it
                self.pathList = reduce( \
                    lambda acc, p: acc+[os.path.join(root,p)] if filename.match(p) else acc, \
                    files, self.pathList )

        self.pathList = map(lambda x: FileScan(x), self.pathList)

    def __iter__(self):
        return iter(self.pathList)

    def __len__(self):
        return len(self.pathList)

    def location(self):
        return super(FileSource, self).location()

    def cleanup(self):
        self.restore()


class VBSSource(DataSource):
    def __init__(self, location):
        # We can support >1 vbs synchronization / FlexBuff
        # by doing it in multiple runtimes
        super(VBSSource, self).__init__(location, runtime=random_word(8))

        SRC  = self.source
        self.pathList = [SRC.path]

        # do we need to do wildcard processing?
        if '*' in SRC.path or '?' in SRC.path:
            if SRC.controlIP != '127.0.0.1':
                raise RuntimeError, "Unfortunately we do not support wildcards in file names on remote systems"
            # Note: the parseVBS has already guaranteed that the path
            # contains no slashes. Do regex special char escaping as well
            # as translating "*" into ".*" and "?" into "."
            path     = copy.copy(SRC.path)
            path     = sub(path, [("\.", "\."), ("\*", ".*"), ("\+", "\+"), ("\?",".")])
            rxRecord = re.compile(r"^"+path+"$")
            rxDisk   = re.compile(r"^disk[0-9]+$")
            rxRecDir = re.compile(r"^/mnt/disk[0-9]+$")
            rxPath   = re.compile(r"^/mnt/disk[0-9]+/(?P<recording>"+path+")$")
            rxFile   = re.compile(r"^"+path+"\.[0-9]{8}$")

            # On the FlexBuff all recordings reside under 
            # /mnt/disk[0-9]+/<recording>
            # Maybe we should filter out only the recordings (1) matching
            # the pattern (d'oh) but also those that actually contain
            # *data*!
            # vlbi_streamer data files are found:
            #   /mnt/disk[0-9]+/<recording>/<recording>.[0-9]{8} 
            #  i.e. files with basename <recording> and an 8-digit sequence
            #  number
            recordingset  = set()
            for (root, dirs, files) in os.walk("/mnt"):
                # in "/mnt" we only consider the "dirs" that match the
                # "disk[0-9]+"
                if root=="/mnt":
                    dirs = filter(lambda x: rxDisk.match(x), dirs)
                    continue
                # In <root>'s matching "/mnt/disk[0-9]+", we only 
                # consider "dirs" that match the recording
                if rxRecDir.match(root):
                    dirs = filter(lambda x: rxRecord.match(x), dirs)
                    continue
                # In <root>'s actually matching
                # /mnt/disk[0-]+/<recording>/ we look for
                # files matching "<recording>.[0-9]{8}"
                mo = rxPath.match(root)
                if mo:
                    # if we find any files matching, the recording
                    # can be added
                    if len(filter(lambda x: rxFile.match(x), files)):
                        recordingset.add( mo.group('recording') )
            self.pathList = list(recordingset)
        self.pathList = map(lambda x: FileScan(x), self.pathList)

    def __iter__(self):
        return iter(self.pathList)

    def __len__(self):
        return len(self.pathList)

    def location(self):
        return super(VBSSource, self).location()

    def cleanup(self):
        self.restore()

## Mark5 I/O board as data source
class InSource(DataSource):
    def __init__(self, location):
        # we do *NOT* want to run 'modeless' (i.e. "mode=none")
        super(InSource, self).__init__(location, modeless=False)

        # we must verify that the jive5ab we're talking to
        # actually HAS an I/O board
        dtsid = self.send_query("dts_id?")
        if not ("mark5" in dtsid[2].lower()):
            raise RuntimeError, "Data Source is not Mark5 - does not have an I/O board"

        # we have only one 'scan'
        # let's generate a scan name that makes some sense
        # like "<date>-<mode>
        self.scanList = [ FileScan('_'.join( [timestampNow()] + self.send_query("mode?")[2:])) ]

    # implement the DataSource part
    def __iter__(self):
        return iter(self.scanList)

    def __len__(self):
        return len(self.scanList)

    def location(self):
        return super(InSource, self).location()

    def cleanup(self):
        self.restore()

## jive5ab interchainqueue as source
class MemSource(DataSource):
    def __init__(self, location):
        # we *DO* want to run 'modeless' (i.e. "mode=none")
        super(MemSource, self).__init__(location, modeless=True, runtime=random_word(9))

        # we have only one 'scan'
        # let's generate a scan name that makes some sense
        # like "<date>-<mode>
        self.scanList = [ FileScan('_'.join( ["mem", timestampNow()])) ]

    # implement the DataSource part
    def __iter__(self):
        return iter(self.scanList)

    def __len__(self):
        return len(self.scanList)

    def location(self):
        return super(MemSource, self).location()

    def cleanup(self):
        self.restore()

#################### the destinations ############################

class FileDest(DataSink):
    def __init__(self, location):
        # Do the transfer in a different runtime
        super(FileDest, self).__init__(location, runtime=random_word(8))
        
        # Split the destination into path/file
        DST                   = self.destination
        (self.dir, self.file) = os.path.split(DST.path)

    def location(self):
        return super(FileDest, self).location()

    # Is the DataSink configured to support >1 output names?
    def multiple_outputs(self):
        # Yes we are if the "self.file" part is null/empty
        return not self.file

    # Compute the output name of the given input.

    # If we were constructed with an explicit file as path, then we return
    # the path we were created with, otherwise the concatenation of self.dir
    # + the input name. Append extension ".m5a" if necessary
    def compute_outputname(self, input):
        if self.file:
            return self.destination.path
        else:
            # have to split input into path/file before appending to *our* dir
            (_dir, file) = os.path.split(input.name())
            # check if the the input has an extension. If not, append it
            (base, ext)  = os.path.splitext(file)
            if not ext:
                ext = ".m5a"
            return os.path.join(self.dir, base+ext)

    def cleanup(self):
        self.restore()

class DiskDest(DataSink):
    def __init__(self, location):
        super(DiskDest, self).__init__(location)

        DST  = self.destination

        # Select the requested bank or VSN, if one was given.
        # Note: bank and VSN are mutually exclusive at most one
        #       of them is actually set
        if DST.bank:
            self.switch_bank(DST.bank)
        if DST.VSN:
            self.switch_vsn(DST.VSN)

    def location(self):
        DST = self.destination
        return super(DiskDest, self).location() + (DST.bank+"/" if DST.bank else (DST.VSN+"/" if DST.VSN else ""))

    # Is the DataSink configured to support >1 output names?
    def multiple_outputs(self):
        # Yes we are if no specific scan (==path) was configured when we
        # were created
        return not self.destination.path

    # Compute the output name of the given input.

    # If we were constructed with an explicit path, then we return the path
    # we were created with, otherwise it will be the basename of the input
    # with extension removed.
    # This means it works for "/full/path/to/file.m5a" as well as "gr036_ef_no0001"
    def compute_outputname(self, input):
        if self.destination.path:
            return self.destination.path
        else:
            # ok, first split into (dir, file)
            (_dir, file) = os.path.split(input.name())
            # strip extension
            return os.path.splitext(file)[0]

    def cleanup(self):
        self.restore()

class VBSDest(DataSink):
    def __init__(self, location):
        # Do the transfer in a different runtime
        super(VBSDest, self).__init__(location, runtime=random_word(8))

    def location(self):
        return super(VBSDest, self).location()

    # Is the DataSink configured to support >1 output names?
    def multiple_outputs(self):
        # Yes we are if no specific scan (==path) was configured when we
        # were created OR if the path was '/dev/null'!
        return not self.destination.path or self.destination.path=='/dev/null'

    # Compute the output name of the given input.

    # If we were constructed with an explicit path, then we return the path
    # we were created with, otherwise it will be the basename of the input
    # with extension removed.
    # This means it works for "/full/path/to/file.m5a" as well as "gr036_ef_no0001"
    def compute_outputname(self, input):
        if self.destination.path:
            return self.destination.path
        else:
            # ok, first split into (dir, file)
            (_dir, file) = os.path.split(input.name())
            # strip extension
            return os.path.splitext(file)[0]

    def cleanup(self):
        self.restore()


#####################################################################################
##
##
##                  The actual transfers
##
##
#####################################################################################


class SourceXFER(object):
    # interface for source xfers
    def __init__(self, source):
        self.DataSource = source

    # start transferring data from scan 'scan' to the destination 'dataip'
    def start(self, scan, dataip):
        raise RuntimeError, "Someone forgot to implement SourceXFER::start()"

    # In case the source did something to the data, sending out a different
    # flavour than taking in, we must be able to tell what it is outputting
    def outputFormat(self):
        raise RuntimeError, "Someone forgot to implement SourceXFER::outputFormat()"

    # return tuple with (start, current, end) if xfer still running,
    # None if transfer is finished
    def progress(self):
        raise RuntimeError, "Someone forgot to implement SourceXFER::progress()"

    # must be cancellable
    def cancel(self):
        raise RuntimeError, "Someone forgot to implement SourceXFER::cancel()"

class DestXFER(object):
    def __init__(self, sink):
        self.DataSink = sink

    # open output for accepting output into 'output'
    def open(self, output):
        raise RuntimeError, "Someone forgot to implement DestXFER::open()"

    # we must be able to take in a different format than was origianally
    # read - a format translation may have taken place
    def setInputFormat(self, fmt):
        raise RuntimeError, "Someone forgot to implement DestXFER::setInputFormat()"

    # return received byte count. Typically the transfer will
    # wait until this number has stabilized, so be sure to return
    # the same number if the transfer is inactive or has finished
    # (in case you can tell)
    def rcv_bytecount(self):
        raise RuntimeError, "Someone forgot to implement DestXFER::rcv_bytecount()"

    # must be cancellable
    def cancel(self):
        raise RuntimeError, "Someone forgot to implement DestXFER::cancel()"


####### Actual concrete transfers

# A disk2file is both ... we must introduce a class variable
# to let the destination part and source path communicate with
# each other
class disk2file(SourceXFER, DestXFER):
    outputFileName = None

    def __init__(self, src_or_dst):
        # look at what flavour we were initialized with to decide
        # which of our base classes should be initialized
        if isinstance(src_or_dst, DataSource):
            self.isSource = True
            SourceXFER.__init__(self, src_or_dst)
        else:
            self.isSource = False
            DestXFER.__init__(self, src_or_dst)

    #### Both types (SourceXFER and DestXFER) should be 
    #### cancellable
    def cancel(self):
        if self.isSource:
            self.DataSource.send_query("reset=abort", Mark5.anyReturn)
        else:
            disk2file.outputFileName = None

    #### This is the SourceXFER part of the transfer
    def outputFormat(self):
        return None

    def start(self, scan, dataip):
        # shorthand to the control interface
        CTRL = self.DataSource

        # disk2file transfer is always coming from a DiskSource
        # (in case it isn't this is an error) so the "scanIds" that
        # are passed into us are really tuples, "(scan number, scan name)"
        (scanNum, scanName) = scan.scanId

        startByte = CTRL.startByte()
        endByte   = CTRL.endByte()

        # Attempt to set the correct scan and verify it did set.
        CTRL.send_query("scan_set={0:d}".format(scanNum), [0])
        reply = CTRL.send_query("scan_set?", [0])
        # If the current disk scan was marked as duplicate, it means
        # that some unique suffix has been appended. We must strip
        # that name to do our consistency checking
        if hasattr(scan, 'duplicate'):
            suffix = uniqSuffix(scanNum)
            if scanName.endswith(suffix):
                # Ok, modify scan name
                # Find the right-most uniqSuffix(). Suppose that by chance
                # the scan with name "name.scan.2" would end up in scan
                # postions #1 and  #2 (duplicated) on the disk pack.
                # then the 2nd uniquefied scan name would be:
                #    "name.scan.2.scan.2"
                # if we then do string.sub(".scan.2", "") it would replace 
                # *both* instances instead of only the last one
                # making our test for the scan's existence on the disk pack
                # fail!
                sidx = scanName.rfind(suffix)
                if sidx<0:
                    raise RuntimeError, "Could not find unique suffix whilst it should be there?!"
                scanName = scanName[0:sidx]
            else:
                raise RuntimeError, \
                        "Scan #{0} ({1}) was marked as duplicate but does not end with expected suffix '{2}'".format( \
                            scanNum, scanName, suffix)
        if not (int(reply[2])==scanNum and reply[3]==scanName):
            raise RuntimeError, "Scan #{0} ({1}) is not that anymore, it is now #{2} ({3})".format( \
                                 scanNum, scanName, int(reply[2]), reply[3])

        CTRL.send_query("disk2file={0}:{1}:{2}:{3}".format( disk2file.outputFileName, \
                startByte if startByte else "", endByte if endByte else "", \
                'w' if (disk2file.outputFileName=="/dev/null" or allowOverwrite) else 'n'), [1])

    def progress(self):
        r = self.DataSource.send_query("disk2file?")
        return None if r[2]=="inactive" else (int(r[5]), int(r[4]), int(r[6]))

    #### This is the DestXFER part of the interface
    
    # The "open()" method in this local xfer stores the output file name
    def open(self, output):
        disk2file.outputFileName = output

    def setInputFormat(self, fmt):
        pass

    def rcv_bytecount(self):
        return 0


        
# file2disk is, like disk2file, both
class file2disk(SourceXFER, DestXFER):
    outputScanName = None
    inputRuntime   = None

    def __init__(self, src_or_dst):
        # look at what flavour we were initialized with to decide
        # which of our base classes should be initialized
        if isinstance(src_or_dst, DataSource):
            self.isSource = True
            SourceXFER.__init__(self, src_or_dst)
            # we must change from arbitrary runtime to
            # runtime
            r = self.DataSource.send_query("runtime?", [0])
            file2disk.inputRuntime = r[2]
            self.DataSource.send_query("runtime=0", [0])
        else:
            self.isSource = False
            DestXFER.__init__(self, src_or_dst)

    #### Both types (SourceXFER and DestXFER) should be 
    #### cancellable
    def cancel(self):
        if self.isSource:
            self.DataSource.send_query("reset=abort", Mark5.anyReturn)
            self.DataSource.send_query("runtime={0}".format(file2disk.inputRuntime), [0])
            file2disk.inputRuntime = None
        else:
            file2disk.outputFileName = None

    #### This is the SourceXFER part of the transfer
    def outputFormat(self):
        return None

    def start(self, scan, dataip):
        CTRL = self.DataSource
        startByte = CTRL.startByte()
        endByte   = CTRL.endByte()
        CTRL.send_query("file2disk={0}:{1}:{2}:{3}".format(scan.name(), \
                (startByte if startByte else ""), (endByte if endByte else ""), \
                            file2disk.outputScanName), [1])

    def progress(self):
        r = self.DataSource.send_query("file2disk?")
        return None if r[2]=="inactive" else (int(r[5]), int(r[4]), int(r[6]))

    #### This is the DestXFER part of the interface

    # The "open()" method in this local xfer creates the 
    # function that will run the actual command, apart from
    # two arguments the ".start()" will supply - the input
    # file name and the actual control interface
    def open(self, outputScanName):
        file2disk.outputScanName = outputScanName

    def setOutputFormat(self, fmt):
        pass

    def rcv_bytecount(self):
        return 0

#### Local cornerturn operations
class spid2file(SourceXFER, DestXFER):
    outputFileName = None

    def __init__(self, src_or_dst):
        # look at what flavour we were initialized with to decide
        # which of our base classes should be initialized
        if isinstance(src_or_dst, DataSource):
            self.isSource = True
            SourceXFER.__init__(self, src_or_dst)

            # Analyze the cornerturning setup. In this case, because there is no
            # receiver, we can forget about the output format
            (self.ct_setup, self.ct_recipe, self.vdif_props, dummy) = ct_setup_commands("spid2file")
            # We can already program the VDIF setup
            map(lambda cmd: self.DataSource.send_query(cmd, [0]), self.ct_setup)
        else:
            self.isSource = False
            DestXFER.__init__(self, src_or_dst)

    #### Both types (SourceXFER and DestXFER) should be 
    #### cancellable
    def cancel(self):
        if self.isSource:
            self.DataSource.send_query("spid2file=disconnect", Mark5.anyReturn)
        else:
            spid2file.outputFileName = None

    #### This is the SourceXFER part of the transfer

    # note: for a local format translation, we can still ignore the output format
    def outputFormat(self):
        return None

    def start(self, scan, dataip):
        # shorthand to the control interface
        CTRL = self.DataSource

        # disk2file transfer is always coming from a DiskSource
        # (in case it isn't this is an error) so the "scanIds" that
        # are passed into us are really tuples, "(scan number, scan name)"
        (scanNum, scanName) = scan.scanId

        startByte = CTRL.startByte()
        endByte   = CTRL.endByte()

        # Attempt to set the correct scan and verify it did set.
        CTRL.send_query("scan_set={0:d}".format(scanNum), [0])
        reply = CTRL.send_query("scan_set?", [0])
        # If the current disk scan was marked as duplicate, it means
        # that some unique suffix has been appended. We must strip
        # that name to do our consistency checking
        if hasattr(scan, 'duplicate'):
            suffix = uniqSuffix(scanNum)
            if scanName.endswith(suffix):
                # Ok, modify scan name
                # Find the right-most uniqSuffix(). Suppose that by chance
                # the scan with name "name.scan.2" would end up in scan
                # postions #1 and  #2 (duplicated) on the disk pack.
                # then the 2nd uniquefied scan name would be:
                #    "name.scan.2.scan.2"
                # if we then do string.sub(".scan.2", "") it would replace 
                # *both* instances instead of only the last one
                # making our test for the scan's existence on the disk pack
                # fail!
                sidx = scanName.rfind(suffix)
                if sidx<0:
                    raise RuntimeError, "Could not find unique suffix whilst it should be there?!"
                scanName = scanName[0:sidx]
            else:
                raise RuntimeError, \
                        "Scan #{0} ({1}) was marked as duplicate but does not end with expected suffix '{2}'".format( \
                            scanNum, scanName, suffix)
        if not (int(reply[2])==scanNum and reply[3]==scanName):
            raise RuntimeError, "Scan #{0} ({1}) is not that anymore, it is now #{2} ({3})".format( \
                                 scanNum, scanName, int(reply[2]), reply[3])

        # Scan is selected, only thing left is to turn the whole thing on
        CTRL.send_query("spid2file=connect:{0}:{1}={2},{3}".format(
                                    self.ct_recipe, self.vdif_props.threads,
                                    spid2file.outputFileName,
                                    'w' if (spid2file.outputFileName=="/dev/null" or allowOverwrite) else 'n'
                                    ), [0])
        CTRL.send_query("spid2file=on:{0}:{1}".format(startByte if startByte else "", endByte if endByte else ""))

    def progress(self):
        r = self.DataSource.send_query("spid2file?")
        #  !spid2file? 0 : active : <start> : <current> : <end>
        #  0           1   2        3         4           5
        # spid2file never terminates automatically so we'll have to
        # go by the numbers ourselves
        (c, s, e) = (int(r[4]), int(r[3]), int(r[5])) if r[2]=="active" else (0, 0, 0)
        return None if c>=e else (c, s, e)

    #### This is the DestXFER part of the interface
    
    # The "open()" method in this local xfer stores the output file name
    def open(self, output):
        spid2file.outputFileName = output

    def setInputFormat(self, fmt):
        pass

    def rcv_bytecount(self):
        return 0


class spif2file(SourceXFER, DestXFER):
    outputFileName = None

    def __init__(self, src_or_dst):
        # look at what flavour we were initialized with to decide
        # which of our base classes should be initialized
        if isinstance(src_or_dst, DataSource):
            self.isSource = True
            SourceXFER.__init__(self, src_or_dst)

            # Analyze the cornerturning setup, forget about the output format; 
            # we don't have to set it because there is no receiving jive5ab
            (self.ct_setup, self.ct_recipe, self.vdif_props, dummy) = ct_setup_commands("spif2file")
            # We can already program the VDIF setup
            map(lambda cmd: self.DataSource.send_query(cmd, [0]), self.ct_setup)
        else:
            self.isSource = False
            DestXFER.__init__(self, src_or_dst)

    #### Both types (SourceXFER and DestXFER) should be 
    #### cancellable
    def cancel(self):
        if self.isSource:
            self.DataSource.send_query("spif2file=disconnect", Mark5.anyReturn)
        else:
            spid2file.outputFileName = None

    #### This is the SourceXFER part of the transfer
    # note: for a local format translation, we can still ignore the output format
    def outputFormat(self):
        return None

    def start(self, scan, dataip):
        # shorthand to the control interface
        CTRL = self.DataSource
        startByte = CTRL.startByte()
        endByte   = CTRL.endByte()

        # Scan is selected, only thing left is to turn the whole thing on
        CTRL.send_query("spif2file=connect:{4}:{0}:{1}={2},{3}".format(
                                    self.ct_recipe, self.vdif_props.threads,
                                    spif2file.outputFileName,
                                    'w' if (spif2file.outputFileName=="/dev/null" or allowOverwrite) else 'n',
                                    scan.name()
                                    ), [0])
        CTRL.send_query("spif2file=on:{0}:{1}".format(startByte if startByte else "", endByte if endByte else ""))

    def progress(self):
        r = self.DataSource.send_query("spif2file?")
        #  !spid2file? 0 : active : <start> : <current> : <end>
        #  0           1   2        3         4           5
        # spid2file never terminates automatically so we'll have to
        # go by the numbers ourselves
        (c, s, e) = (int(r[4]), int(r[3]), int(r[5])) if r[2]=="active" else (0, 0, 0)
        return None if c>=e else (c, s, e)

    #### This is the DestXFER part of the interface
    
    # The "open()" method in this local xfer stores the output file name
    def open(self, output):
        spif2file.outputFileName = output

    def setInputFormat(self, fmt):
        pass

    def rcv_bytecount(self):
        return 0

#### Some helper functions for dealing with IN/MEM style
#### 'paths' - the path can be a runtime in seconds or
#### a runtime in amount of bytes
def mk_tstat_cmp(l, h, fn):
    def act_tstat_cmp(tsnew, tsold):
        if queries:
            print "act_tstat_cmp/tsnew=",tsnew
            print "              tsold=",tsold
        if len(tsnew)<5 or len(tsold)<5:
            return None
        cur = fn(tsnew, tsold)
        if queries:
            print "              cur  =",cur
        return (cur, l, h) if cur<h else None
    return act_tstat_cmp

## Parse the path for runtime by time, bytes or indefinite
## we'll add a function
def add_done_yet(obj, path):
    # Set up a function that detects wether we're done or not
    # if there is no 'path', we run 'indefinitely'.
    # If there is a 'path' it's either an amount of bytes
    # or an amount of seconds that we should transfer
    # Progress is measured by comparing different fields 
    # from "tstat=" command (so the values come from 
    # jive5ab, not from us)
    #    !tstat = 0 : <transfer> : <time> : <step1> : <count1> : ...
    #    0        1   2            3        4         5
    if path:
        mo   = rxAmount.match( path )
        amt  = int(mo.group('amount'))
        unit = mo.group('unit')
        if unit=='s':
            # runtime in seconds
            obj.done_yet = mk_tstat_cmp(0, amt, lambda n, o: float(n[2]) - float(o[2]))
        else:
            # runtime in bytes
            obj.done_yet = mk_tstat_cmp(0, amt*scaleTableBinary[unit], lambda n, o: int(n[5]) - int(o[5]))
    else:
        # run indefinitely (well, until 2**63 bytes have been
        # transferred)
        obj.done_yet = mk_tstat_cmp(0, 2**63, lambda n, o: int(n[5]) - int(o[5]))
    

# in2file is also a simple, local transfer, which is both SRC and DST
class in2file(SourceXFER, DestXFER):
    outputFileName = None
    inputRuntime   = None

    def __init__(self, src_or_dst):
        # look at what flavour we were initialized with to decide
        # which of our base classes should be initialized
        if isinstance(src_or_dst, DataSource):
            self.isSource = True
            SourceXFER.__init__(self, src_or_dst)
            # we must change from arbitrary runtime to
            # runtime '0', because that one has access to the h/w
            r = self.DataSource.send_query("runtime?", [0])
            in2file.inputRuntime = r[2]
            self.DataSource.send_query("runtime=0", [0])
            add_done_yet(self, self.DataSource.source.path)
        else:
            self.isSource = False
            DestXFER.__init__(self, src_or_dst)

    #### Both types (SourceXFER and DestXFER) should be 
    #### cancellable
    def cancel(self):
        if self.isSource:
            self.DataSource.send_query("in2file=disconnect", Mark5.anyReturn)
            self.DataSource.send_query("runtime={0}".format(in2file.inputRuntime), [0])
            in2file.inputRuntime = None
        else:
            in2file.outputFileName = None

    #### This is the SourceXFER part of the transfer
    # for a local transfer, the output data format is irrelevant
    def outputFormat(self):
        return None

    def start(self, scan, dataip):
        CTRL      = self.DataSource
        CTRL.send_query("in2file=connect:{0}".format(in2file.outputFileName, [1]))
        CTRL.send_query("in2file=on")
        self.oldtstat = CTRL.send_query("tstat=")

    def progress(self):
        return self.done_yet(self.DataSource.send_query("tstat="), self.oldtstat)

    #### This is the DestXFER part of the interface

    # The "open()" method in this local xfer creates the 
    # function that will run the actual command, apart from
    # two arguments the ".start()" will supply - the input
    # file name and the actual control interface
    def open(self, outputScanName):
        in2file.outputFileName = outputScanName

    def setInputFormat(self, fmt):
        pass

    def rcv_bytecount(self):
        return 0

### in2disk is basically "record=on:scan"
class in2disk(SourceXFER, DestXFER):
    outputScanName = None
    inputRuntime   = None

    def __init__(self, src_or_dst):
        # look at what flavour we were initialized with to decide
        # which of our base classes should be initialized
        if isinstance(src_or_dst, DataSource):
            self.isSource = True
            SourceXFER.__init__(self, src_or_dst)
            # we must change from arbitrary runtime to
            # runtime '0', because that one has access to the h/w
            r = self.DataSource.send_query("runtime?", [0])
            in2disk.inputRuntime = r[2]
            self.DataSource.send_query("runtime=0", [0])
            add_done_yet(self, self.DataSource.source.path)
        else:
            self.isSource = False
            DestXFER.__init__(self, src_or_dst)

    #### Both types (SourceXFER and DestXFER) should be 
    #### cancellable
    def cancel(self):
        if self.isSource:
            self.DataSource.send_query("record=off", Mark5.anyReturn)
            self.DataSource.send_query("runtime={0}".format(in2file.inputRuntime), [0])
            in2disk.inputRuntime = None
        else:
            in2disk.outputScanName = None

    #### This is the SourceXFER part of the transfer
    # local transfer thus output format is irrelevant
    def outputFormat(self):
        return None

    def start(self, scan, dataip):
        CTRL      = self.DataSource
        CTRL.send_query("record=on:{0}".format(in2disk.outputScanName))
        self.oldtstat = CTRL.send_query("tstat=")

    def progress(self):
        return self.done_yet(self.DataSource.send_query("tstat="), self.oldtstat)

    #### This is the DestXFER part of the interface

    # The "open()" method in this local xfer creates the 
    # function that will run the actual command, apart from
    # two arguments the ".start()" will supply - the input
    # file name and the actual control interface
    def open(self, outputScanName):
        in2disk.outputScanName = outputScanName

    def setInputFormat(self, fmt):
        pass

    def rcv_bytecount(self):
        return 0

## split input (corner turn directly from telescope)
class spin2file(SourceXFER, DestXFER):
    outputFileName = None

    def __init__(self, src_or_dst):
        # look at what flavour we were initialized with to decide
        # which of our base classes should be initialized
        if isinstance(src_or_dst, DataSource):
            self.isSource = True
            SourceXFER.__init__(self, src_or_dst)

            # we must change from arbitrary runtime to
            # runtime '0', because that one has access to the h/w
            r = self.DataSource.send_query("runtime?", [0])
            spin2file.inputRuntime = r[2]
            self.DataSource.send_query("runtime=0", [0])

            # Analyze the "in://path" 'path' and form
            # a termination condition
            add_done_yet(self, self.DataSource.source.path)

            # Analyze the cornerturning setup, forget about the output format;
            # we don't have to set it because there is no receiving program
            (self.ct_setup, self.ct_recipe, self.vdif_props, dummy) = ct_setup_commands("spin2file")
            # We can already program the VDIF setup
            map(lambda cmd: self.DataSource.send_query(cmd, [0]), self.ct_setup)
        else:
            self.isSource = False
            DestXFER.__init__(self, src_or_dst)

    #### Both types (SourceXFER and DestXFER) should be 
    #### cancellable
    def cancel(self):
        if self.isSource:
            self.DataSource.send_query("spin2file=disconnect", Mark5.anyReturn)
            self.DataSource.send_query("runtime={0}".format(spin2file.inputRuntime), [0])
        else:
            spin2file.outputFileName = None

    #### This is the SourceXFER part of the transfer

    # note: for a local format translation, we can still ignore the output format
    def outputFormat(self):
        return None

    def start(self, scan, dataip):
       # shorthand to the control interface
        CTRL = self.DataSource
        # Scan is selected, only thing left is to turn the whole thing on
        CTRL.send_query("spin2file=connect:{0}:{1}={2},{3}".format(
            self.ct_recipe, self.vdif_props.threads,
            spin2file.outputFileName,
            'w' if (spin2file.outputFileName=="/dev/null" or allowOverwrite) else 'n'
            ), [0])
        CTRL.send_query("spin2file=on")
        self.oldtstat = CTRL.send_query("tstat=")

    def progress(self):
        return self.done_yet(self.DataSource.send_query("tstat="), self.oldtstat)

    #### This is the DestXFER part of the interface

    # The "open()" method in this local xfer stores the output file name
    def open(self, output):
        spin2file.outputFileName = output

    def setInputFormat(self, fmt):
        pass

    def rcv_bytecount(self):
        return 0


# likewise for mem2file. it is also a simple, local transfer, which is both SRC and DST
class mem2file(SourceXFER, DestXFER):
    outputScanName = None

    def __init__(self, src_or_dst):
        # look at what flavour we were initialized with to decide
        # which of our base classes should be initialized
        if isinstance(src_or_dst, DataSource):
            self.isSource = True
            SourceXFER.__init__(self, src_or_dst)
            add_done_yet(self, self.DataSource.source.path)
        else:
            self.isSource = False
            DestXFER.__init__(self, src_or_dst)

    #### Both types (SourceXFER and DestXFER) should be 
    #### cancellable
    def cancel(self):
        if self.isSource:
            self.DataSource.send_query("mem2file=close", Mark5.anyReturn)
            file2disk.inputRuntime = None
        else:
            file2disk.outputFileName = None

    #### This is the SourceXFER part of the transfer
    # for local transfer, output data format is irrelevant
    def outputFormat(self):
        return None

    def start(self, scan, dataip):
        CTRL      = self.DataSource
        CTRL.send_query("mem2file=on:{0}".format(mem2file.outputScanName, [1]))
        self.oldtstat = CTRL.send_query("tstat=")

    def progress(self):
        return self.done_yet(self.DataSource.send_query("tstat="), self.oldtstat)

    #### This is the DestXFER part of the interface

    # The "open()" method in this local xfer creates the 
    # function that will run the actual command, apart from
    # two arguments the ".start()" will supply - the input
    # file name and the actual control interface
    def open(self, outputScanName):
        mem2file.outputScanName = outputScanName

    def setInputFormat(self, fmt):
        pass

    def rcv_bytecount(self):
        return 0


## disk2net

class disk2net(SourceXFER):
    def __init__(self, datasource):
        super(disk2net, self).__init__( datasource )

    # no format translation
    def outputFormat(self):
        return None

    def start(self, scan, dataip):
        # shorthand to the control interface
        CTRL = self.DataSource

        # disk2net transfer is always coming from a DiskSource
        # (in case it isn't this is an error) so the "scanIds" that
        # are passed into us are really tuples, "(scan number, scan name)"
        (scanNum, scanName) = scan.scanId

        startByte = CTRL.startByte()
        endByte   = CTRL.endByte()

        # Attempt to set the correct scan and verify it did set.
        CTRL.send_query("scan_set={0:d}".format(scanNum), [0])
        reply = CTRL.send_query("scan_set?", [0])
        if hasattr(scan, 'duplicate'):
            suffix = uniqSuffix(scanNum)
            if scanName.endswith(suffix):
                # Ok, modify scan name
                # Find the right-most uniqSuffix(). Suppose that by chance
                # the scan with name "name.scan.2" would end up in scan
                # postions #1 and  #2 (duplicated) on the disk pack.
                # then the 2nd uniquefied scan name would be:
                #    "name.scan.2.scan.2"
                # if we then do string.sub(".scan.2", "") it would replace 
                # *both* instances instead of only the last one
                # making our test for the scan's existence on the disk pack
                # fail!
                sidx = scanName.rfind(suffix)
                if sidx<0:
                    raise RuntimeError, "Could not find unique suffix whilst it should be there?!"
                scanName = scanName[0:sidx]
            else:
                raise RuntimeError, \
                        "Scan #{0} ({1}) was marked as duplicate but does not end with expected suffix '{2}'".format( \
                            scanNum, scanName, suffix)
        if not (int(reply[2])==scanNum and reply[3]==scanName):
            raise RuntimeError, "Scan #{0} ({1}) is not that anymore, it is now #{2} ({3})".format( \
                                 scanNum, scanName, int(reply[2]), reply[3])

        # Attempt to connect to remote side
        CTRL.send_query("disk2net=connect:{0:s}".format(dataip), [0,1])

        # And let it flow!
        # HV: 9 dec 2014  Roger H. finds that, sometimes, the connect
        #                 initiated by the previous command takes
        #                 so long that disk2net isn't connected
        #                 yet by the time we send it the "=on" command.
        while True:
            r = CTRL.send_query("disk2net?", [0])
            if "connected" in r:
                break
            print ">>>> Waiting for disk2net to connect"
            time.sleep(1)
        CTRL.send_query("disk2net=on:{0}:{1}".format(startByte if startByte else "", endByte if endByte else ""), [0])

        # HV: 9 dec 2014  GRRRR. Roger H. finds that, sometimes, 
        #                 "disk2net=on" takes so long that it remains
        #                 in the connected state by the time we get to the
        #                 .progress(self) method. So we must wait here
        #                 for the status to become active
        while True:
            r = CTRL.send_query("disk2net?", [0])
            if "active" in r:
                break
            print ">>>> Waiting for disk2net to start"
            time.sleep(1)

    def progress(self):
        r = self.DataSource.send_query("disk2net?")
        return None if r[2]=="inactive" else (int(r[5]), int(r[4]), int(r[6]))

    def cancel(self):
        self.DataSource.send_query("disk2net=disconnect", Mark5.anyReturn)


class file2net(SourceXFER):
    def __init__(self, datasource):
        super(file2net, self).__init__( datasource )

    # no format translation
    def outputFormat(self):
        return None

    def start(self, scan, dataip):
        # shorthand to the control interface
        CTRL = self.DataSource

        startByte = CTRL.startByte()
        endByte   = CTRL.endByte()

        CTRL.send_query("file2net=connect:{0:s}:{1:s}".format(dataip, scan.name()), [0])
        CTRL.send_query("file2net=on:{0}:{1}".format(startByte if startByte else "", endByte if endByte else "", [0]))

    def progress(self):
        # Wait until the "file2net?" returns either "active" or "inactive"
        while True:
            r = self.DataSource.send_query("file2net?")
            if "active" in r[2]:
                break
            print "file2net: waiting for connection to be established"
            time.sleep(1)
        return None if (len(r)<7 or r[2]=="inactive") else (int(r[5]), int(r[4]), int(r[6]))

    def cancel(self):
        self.DataSource.send_query("file2net=disconnect", Mark5.anyReturn)

class vbs2net(SourceXFER):
    def __init__(self, datasource):
        super(vbs2net, self).__init__( datasource )
        # when configuring the number of readers/writers we make some
        # assumptions:
        #   * reading vbs disks is faster than writing (thus nDiskReader <
        #     nDiskWriter)
        # NOTE: 'nthread' is a global parameter, settable from the command
        #       line
        self.DataSource.send_query("vbs2net=nthread:{0}:{1}".format(nthread+1, nthread))

    # no format translation
    def outputFormat(self):
        return None

    def start(self, scan, dataip):
        self.DataSource.send_query("vbs2net=connect:{0}:{1}".format(scan.name(), dataip), [0])

    def progress(self):
        r = self.DataSource.send_query("tstat=")
        # we don't know the length of the vbs recording (yet) so let's put
        # in something such that it's always ~98%
        if r[3]!="vbs2net":
            return None
        c = int(r[5])
        return (c, 0, c + max(1, int(float(c)*0.02)))

    def cancel(self):
        self.DataSource.send_query("vbs2net=disconnect", Mark5.anyReturn)


class in2net(SourceXFER):
    def __init__(self, datasource):
        super(in2net, self).__init__( datasource )
        add_done_yet(self, self.DataSource.source.path)

    # no format translation
    def outputFormat(self):
        return None

    def start(self, scan, dataip):
        CTRL = self.DataSource
        CTRL.send_query("in2net=connect:{0}".format(dataip), [0])
        CTRL.send_query("in2net=on", [0])
        self.oldtstat = CTRL.send_query("tstat=")

    def progress(self):
        return self.done_yet(self.DataSource.send_query("tstat="), self.oldtstat)

    def cancel(self):
        self.DataSource.send_query("in2net=disconnect", Mark5.anyReturn)

class mem2net(SourceXFER):
    def __init__(self, datasource):
        super(mem2net, self).__init__( datasource )
        add_done_yet(self, self.DataSource.source.path)

    # no format translation
    def outputFormat(self):
        return None

    def start(self, scan, dataip):
        CTRL = self.DataSource
        CTRL.send_query("mem2net=connect:{0}".format(dataip), [0])
        CTRL.send_query("mem2net=on", [0])
        self.oldtstat = CTRL.send_query("tstat=")

    def progress(self):
        return self.done_yet(self.DataSource.send_query("tstat="), self.oldtstat)

    def cancel(self):
        self.DataSource.send_query("mem2net=disconnect", Mark5.anyReturn)

# would it be possible to let spif2net look at the
# 'datasource' instance and set itself up for
# spid2net, spif2net and spin2net?
class split2net(SourceXFER):
    def __init__(self, datasource):
        super(split2net, self).__init__( datasource )

        # Check our actual datasource
        if isinstance(datasource, DiskSource):
            self.ct_cmd = "spid2net"
        elif isinstance(datasource, FileSource):
            self.ct_cmd = "spif2net"
        elif isinstance(datasource, InSource):
            self.ct_cmd = "spin2net"

            # we must change from arbitrary runtime to
            # runtime '0', because that one has access to the h/w
            r = self.DataSource.send_query("runtime?", [0])
            self.inputRuntime = r[2]
            self.DataSource.send_query("runtime=0", [0])

            # Analyze the "in://path" 'path' and form
            # a termination condition
            add_done_yet(self, self.DataSource.source.path)
        else:
            raise RuntimeError, "Unsupported input data source for split2net {0}".format(datasource)

        # Analyze the cornerturning setup
        (self.ct_setup, self.ct_recipe, self.vdif_props, self.oFmt) = ct_setup_commands(self.ct_cmd)
        # We can already program the VDIF setup
        map(lambda cmd: self.DataSource.send_query(cmd, [0]), self.ct_setup)

    # data format translation!
    def outputFormat(self):
        return self.oFmt

    def start(self, scan, dataip):
        CTRL = self.DataSource

        supportSEByte = self.ct_cmd in ["spid2net", "spif2net"]
        sByte = CTRL.startByte() if supportSEByte else None
        eByte = CTRL.endByte()   if supportSEByte else None

        # When doing transfer from disk, we have to do some more work
        if self.ct_cmd=="spid2net":
            # For transfers from disk, the "scanIds" that
            # are passed into us are really tuples, "(scan number, scan name)"
            (scanNum, scanName) = scan.scanId

            # Attempt to set the correct scan and verify it did set.
            CTRL.send_query("scan_set={0:d}".format(scanNum), [0])
            reply = CTRL.send_query("scan_set?", [0])
            # If the current disk scan was marked as duplicate, it means
            # that some unique suffix has been appended. We must strip
            # that name to do our consistency checking
            if hasattr(scan, 'duplicate'):
                suffix = uniqSuffix(scanNum)
                if scanName.endswith(suffix):
                    # Ok, modify scan name
                    # Find the right-most uniqSuffix(). Suppose that by chance
                    # the scan with name "name.scan.2" would end up in scan
                    # postions #1 and  #2 (duplicated) on the disk pack.
                    # then the 2nd uniquefied scan name would be:
                    #    "name.scan.2.scan.2"
                    # if we then do string.sub(".scan.2", "") it would replace 
                    # *both* instances instead of only the last one
                    # making our test for the scan's existence on the disk pack
                    # fail!
                    sidx = scanName.rfind(suffix)
                    if sidx<0:
                        raise RuntimeError, "Could not find unique suffix whilst it should be there?!"
                    scanName = scanName[0:sidx]
                else:
                    raise RuntimeError, \
                            "Scan #{0} ({1}) was marked as duplicate but does not end with expected suffix '{2}'".format( \
                                scanNum, scanName, suffix)
            if not (int(reply[2])==scanNum and reply[3]==scanName):
                raise RuntimeError, "Scan #{0} ({1}) is not that anymore, it is now #{2} ({3})".format( \
                                     scanNum, scanName, int(reply[2]), reply[3])

        # (potential)scan is selected, only thing left is to turn the whole thing on
        # note that spif2net has a slightly different format:
        #  spin2net = connect : <splitmethod> : <threads>=<dest>
        #  spid2net = connect : <splitmethod> : <threads>=<dest>
        #  spif2net = connect : <filename>,r : <splitmethod> : <threads>=<dest>
        if self.ct_cmd == "spif2net":
            fmt = "{ct_cmd} = connect : {filename} : {splitmethod} : {threads}={dest}"
        else:
            fmt = "{ct_cmd} = connect : {splitmethod} : {threads}={dest}"
        CTRL.send_query(fmt.format( ct_cmd = self.ct_cmd, splitmethod = self.ct_recipe,
                                    threads = self.vdif_props.threads, dest = dataip,
                                    filename = scan.name()
                                    ), [0])
        CTRL.send_query("{ct_cmd}=on:{0}:{1}".format(sByte if sByte else "", eByte if eByte else "", ct_cmd=self.ct_cmd), [0])
        if self.ct_cmd == "spin2net":
            self.oldtstat = CTRL.send_query("tstat=")

    def progress(self):
        CTRL = self.DataSource
        if self.ct_cmd == "spin2net":
            return self.done_yet(CTRL.send_query("tstat="), self.oldtstat)
        else:
            r = CTRL.send_query(self.ct_cmd+"?")
            #  !sp...2net? 0 : active : <start> : <current> : <end>
            #  0           1   2        3         4           5
            # spid2file never terminates automatically so we'll have to
            # go by the numbers ourselves
            (c, s, e) = (int(r[4]), int(r[3]), int(r[5])) if r[2]=="active" else (0, 0, 0)
            return None if c>=e else (c, s, e)

    def cancel(self):
        self.DataSource.send_query("{0}=disconnect".format(self.ct_cmd), Mark5.anyReturn)
        if self.ct_cmd == "spin2net":
            self.DataSource.send_query("runtime={0}".format(self.inputRuntime), [0])



class net2disk(DestXFER):
    def __init__(self, datasink):
        super(net2disk, self).__init__( datasink )

    def open(self, output):
        self.DataSink.send_query("net2disk=open:{0:s}".format(output), [0])

    def setInputFormat(self, fmt):
        if not fmt is None:
            self.DataSink.send_query("mode={0}".format(fmt), [0])

    def cancel(self):
        self.DataSink.send_query("net2disk=close", Mark5.anyReturn)

    def rcv_bytecount(self):
        # net2disk?  replies with:
        # net2disk? 0 : <status> : <scan nr> : <scan name> : <bytes>
        # 0         1   2          3           4             5
        r = self.DataSink.send_query("net2disk?", [0])
        return 0 if (r[2]=="inactive" or len(r)<6) else int(r[5])

class net2file(DestXFER):
    def __init__(self, datasink):
        super(net2file, self).__init__( datasink )

    def open(self, output):
        self.DataSink.send_query("net2file=open:{0:s},{1}".format(output, 'w' if (output=="/dev/null" or allowOverwrite) else 'n'), [0])

    def setInputFormat(self, fmt):
        if not fmt is None:
            self.DataSink.send_query("mode={0}".format(fmt), [0])

    def rcv_bytecount(self):
        r = self.DataSink.send_query("net2file?")
        # this will currently fail, have to look into jive5ab code
        return 0 if r[2]=="inactive" or len(r)<7 else int(r[6])

    def cancel(self):
        self.DataSink.send_query("net2file=close", Mark5.anyReturn)
        

class vbs_record(DestXFER):
    def __init__(self, datasink):
        super(vbs_record, self).__init__( datasink )

        # at the recorder, configure >1 disk writers
        self.DataSink.send_query("record=nthread:1:4", [0])

        # Also configure a different blocksize - the vbs file size
        self.DataSink.send_query("net_protocol=::256M:8")

        # default recording mode
        self.mode = "ext:0xffffffff"

    def setInputFormat(self, fmt):
        if not fmt is None:
            self.mode = fmt

    def open(self, output):
        # start a recording on the FlexBuff
        # apparently we do need a non-empty mode for that
        #self.DataSink.send_query("mode=ext:0xffffffff", [0])
        self.DataSink.send_query("mode={0}".format(self.mode), [0])
        self.DataSink.send_query("record=on:{0:s}".format(output), [0])

    def rcv_bytecount(self):
        return 0

    def cancel(self):
        self.DataSink.send_query("record=off", Mark5.anyReturn)
        self.DataSink.send_query("mode=none", [0])


class net2vbs(DestXFER):
    def __init__(self, datasink):
        super(net2vbs, self).__init__( datasink )

        # when configuring the number of readers/writers we make some
        # assumptions:
        #   * reading vbs disks is faster than writing (thus nDiskReader <
        #     nDiskWriter)
        #   * the number of netwriters == netreaders so they'll be a nice 
        #     balanced match
        # configure number of netreaders + diskwriters at the receiving end
        # NOTE: 'nthread' is a global parameter which is settable from the
        #       command line
        self.DataSink.send_query("net2vbs=nthread:{0}:{1}".format(nthread, max(nthread+1, 8)), [0])

    def setInputFormat(self, fmt):
        pass

    def open(self, output):
        # We ignore the output name because the "sync" method will send the
        # file name in each synchronization transfer
        self.DataSink.send_query("net2vbs=open", [0])

    def rcv_bytecount(self):
        return 0

    def cancel(self):
        self.DataSink.send_query("net2vbs=close", Mark5.anyReturn, timeout=10)


############################################################################
##
##  All possible transfer end points have been defined, now we patch
##  them up together to form the supported transfers
##
############################################################################


##### lcl transfers only allowed if media are different
def lcl_xfer(src, dst):
    matrix = {
        (media_type.DISK, media_type.FILE): (disk2file, DiskSource, disk2file, FileDest),
        (media_type.FILE, media_type.DISK): (file2disk, FileSource, file2disk, DiskDest),
        (media_type.IN,   media_type.FILE): (in2file,   InSource,   in2file,   FileDest),
        (media_type.IN,   media_type.DISK): (in2disk,   InSource,   in2disk,   DiskDest),
        (media_type.MEM,  media_type.FILE): (mem2file,  MemSource,  mem2file,  FileDest)
    }
    key = (src.mediaType, dst.mediaType)
    if not key in matrix:
        raise ValueError, "Unsupported local transfer {0} => {1}".format(src.mediaType, dst.mediaType)
    return matrix[ key ]

## local transfer with cornerturning
def lcl_ct_xfer(src, dst):
    matrix = {
        (media_type.DISK, media_type.FILE): (spid2file, DiskSource, spid2file, FileDest),
        (media_type.FILE, media_type.FILE): (spif2file, FileSource, spif2file, FileDest),
        (media_type.IN,   media_type.FILE): (spin2file, FileSource, spin2file, FileDest)
    }
    key = (src.mediaType, dst.mediaType)
    if not key in matrix:
        raise ValueError, "Unsupported local corner turning transfer {0} => {1}".format(src.mediaType, dst.mediaType)
    return matrix[ key ]

#### The remote transfers: *2net + net2*
# here the media may be identical
def remote_xfer(src, dst):
    matrix = {
        (media_type.DISK, media_type.DISK): (disk2net, DiskSource, net2disk,   DiskDest),
        (media_type.DISK, media_type.FILE): (disk2net, DiskSource, net2file,   FileDest),
        (media_type.FILE, media_type.DISK): (file2net, FileSource, net2disk,   DiskDest),
        (media_type.FILE, media_type.FILE): (file2net, FileSource, net2file,   FileDest),
        (media_type.IN,   media_type.DISK): (in2net,   InSource,   net2disk,   DiskDest),
        (media_type.IN,   media_type.FILE): (in2net,   InSource,   net2file,   FileDest),
        (media_type.IN,   media_type.VBS):  (in2net,   InSource,   vbs_record, FileDest),
        (media_type.MEM,  media_type.DISK): (mem2net,  MemSource,  net2disk,   DiskDest),
        (media_type.MEM,  media_type.FILE): (mem2net,  MemSource,  net2file,   FileDest),
        (media_type.FILE, media_type.VBS):  (file2net, FileSource, vbs_record, VBSDest),
        (media_type.DISK, media_type.VBS):  (disk2net, DiskSource, vbs_record, VBSDest),
        (media_type.VBS,  media_type.VBS):  (vbs2net,  VBSSource,  net2vbs,    VBSDest),
    }
    key = (src.mediaType, dst.mediaType)
    if not key in matrix:
        raise ValueError, "Unsupported remote transfer {0} => {1}".format(src.mediaType, dst.mediaType)
    return matrix[ key ]

# remote corner turners
def remote_ct_xfer(src, dst):
    matrix = {
        (media_type.DISK, media_type.DISK): (split2net, DiskSource, net2disk,   DiskDest),
        (media_type.DISK, media_type.FILE): (split2net, DiskSource, net2file,   FileDest),
        (media_type.DISK, media_type.VBS):  (split2net, DiskSource, vbs_record, VBSDest),
        (media_type.FILE, media_type.DISK): (split2net, FileSource, net2disk,   DiskDest),
        (media_type.FILE, media_type.FILE): (split2net, FileSource, net2file,   FileDest),
        (media_type.FILE, media_type.VBS):  (split2net, FileSource, vbs_record, VBSDest),
        (media_type.IN,   media_type.DISK): (split2net, InSource,   net2disk,   DiskDest),
        (media_type.IN,   media_type.FILE): (split2net, InSource,   net2file,   FileDest),
        (media_type.IN,   media_type.VBS):  (split2net, InSource,   net2file,   FileDest),
    }
    key = (src.mediaType, dst.mediaType)
    if not key in matrix:
        raise ValueError, "Unsupported remote transfer {0} => {1}".format(src.mediaType, dst.mediaType)
    return matrix[ key ]

# One entry point which decides if it's a local or a remote transfer
# Will return a quad-tuple with type constructors:
#    (src_xfer_type, src_type, dst_xfer_type, dst_type)
#
# The calling code can construct the DataSource and DataSink from
# the 'src_type' and 'dst_type'. Then loop over all the entries
# in the DataSource and transfer them to the DataSink, using
# the transfer types to set up the source, destination end points
def xfer_selector(src, dst):
    # we have a matrix of endpoints (disk->file, file->disk, etc)
    # and the source/destination ip addresses; now we 
    # decide which transfers to choose
    #  (e.g. "disk(local) -> file(local) => disk2file"
    #        "disk(X)     -> file(Y)     => disk2net + net2file"
    matrix = {
            (True,  False):  lcl_xfer,
            (True,  True ):  lcl_ct_xfer,
            (False, False):  remote_xfer,
            (False, True):   remote_ct_xfer
        }
    lcl = src.controlIP == dst.controlIP and src.controlPort == dst.controlPort
    return matrix[ (lcl, do_corner)  ](src, dst)


## context manager for the transfer type
class actual_xfer(object):
    def __init__(self, sx, dx):
        self.sourceXFER = sx
        self.destXFER   = dx

    def __enter__(self):
        return self

    def __exit__(self, type, value, traceback):
        self.sourceXFER.cancel()
        self.destXFER.cancel()

def attr(obj):
    import inspect
    return filter(lambda x: x[0][0]!='_', inspect.getmembers(obj, lambda x: not inspect.ismethod(x)))

## context manager for a transfer - this means we have 
## the option of doing a clean shutdown
class xfer_context:
    def __init__(self, src, dst):
        self.srcLocation = src
        self.dstLocation = dst
        # Upon construction get the 4 types of the objects we'll need for
        # the transfer
        (self.sxtype, self.stype, self.dxtype, self.dtype) = xfer_selector(self.srcLocation, self.dstLocation)

    def __enter__(self):
        # Upon entering the context, we create the DataSource and DataSink objects
        self.dataSource = self.stype(self.srcLocation)
        self.dataSink   = self.dtype(self.dstLocation)
        # Check if this will work
        if len(self.dataSource)>1 and not self.dataSink.multiple_outputs():
            raise RuntimeError, "Source specifies >1 scan but destination is explicitly set"
        return self

    def __exit__(self, tp, val, tb):
        self.dataSource.cleanup()
        self.dataSink.cleanup()
        if not (tp is None and val is None and tb is None):
            if queries:
                print traceback.print_exception(tp, val, tb)
            else:
                print val
        return True

    def __call__(self):
        # Ok, we're requested to actually do the transfers
        dataSource = self.dataSource
        dataSink   = self.dataSink
        with actual_xfer(self.sxtype(dataSource), self.dxtype(dataSink)) as xfer:
            sxfer = xfer.sourceXFER
            dxfer = xfer.destXFER

            # configure different input format for the receiver, in case it's not the same as
            # the source data format [ie cornerturning data format X into legacy VDIF]
            dxfer.setInputFormat( sxfer.outputFormat() )

            for scan in dataSource:
                outname = dataSink.compute_outputname(scan)
                print dataSource.location()+scan.name(), "=>", dataSink.location()+outname
                dxfer.open(outname)
                sxfer.start(scan, dataSink.dataIP())

                progress = Progress(45) if verbose else DummyProgress()
                while True:
                    p = sxfer.progress()
                    if not p:
                        break
                    progress(*p)
                    time.sleep(1)
                oldbytes = dxfer.rcv_bytecount()
                progress.say("Waiting for remote end to flush ... "+str(oldbytes))
                while True:
                    time.sleep(1)
                    newbytes = dxfer.rcv_bytecount()
                    if newbytes==oldbytes:
                        break
                    oldbytes = newbytes
                    progress.say("Waiting for remote end to flush ... "+str(oldbytes))
                sxfer.cancel()
                dxfer.cancel()
                progress.done()
                # give UDT some time to close the listening file descriptor ...
                time.sleep( 4 )


class catcher(object):
    def __init__(self):
        pass

    def __enter__(self):
        return self

    def __exit__(self, tp, val, tb):
        if not (tp is None and val is None and tb is None):
            if queries:
                print traceback.print_exception(tp, val, tb)
            else:
                print val
        return True

# returns None if the argument wasn't present, tp(<value>) if it was
# (such that it will give an exception if e.g. you expect int but
#  the user didn't pass a valid int
def get_val(arg, tp=str):
    conversion_error = False
    try:
        # is 'arg' given?
        aidx = sys.argv.index(arg)  # raises ValueError if not found FFS
        aval = sys.argv[aidx+1]     # raises IndexError

        # Check it doesn't start with a '-'!
        if aval[0]=='-':
            raise RuntimeError, "Option %s expects argument, got another option '%s'" % (arg, aval)

        # remove those arguments
        del sys.argv[aidx]; del sys.argv[aidx]
        # now set 'conversion_error' to True because the following
        # statement could (also) raise a ValueError (like the
        # "sys.argv.index()"). FFS Python! So we must take measures to tell
        # them apart
        conversion_error = True
        return tp(aval)
    except ValueError:
        if conversion_error:
            raise
        # no 'arg' given, don't complain
        return None
    except IndexError:
        # Mission option value to option
        raise RuntimeError, "Mission optionvalue to {0}".format(arg)



##################
# the main program
##################

if __name__ == "__main__":
    #########################
    ## Check command line
    #########################

    # Was '-h' requested?
    if len(sys.argv)==1 or '-h' in sys.argv:
        usage()
        sys.exit( 0 )

    # Or maybe '-v' (version)
    if '-v' in sys.argv:
        print version
        sys.exit( 0 )

    # before actually starting to process the args ... we must find the "-p
    # <port>" and extract it manually (the alternative would be to say
    # "p=<port>" but that's a bit ugly and looks too much like dd(1).
    p = get_val('-p', int)
    if p:
        dataport = p
    m = get_val('-m', int)
    if m:
        if m<64:
            raise RuntimeError, "Value '{0}' for MTU is lower than ethernet minimum of 64".format(m)
        if m<1500:
            print "WARN: mtu set to value <1500. Probably negative impact on transfer speed"
        mtu = m
    n = get_val('-n', int)
    if n:
        if n<=1:
            raise RuntimeError, "Illegal number of parallel file transfers: {0}".format(n)
        nthread = n
    # Check if a rate was given
    rate = get_val('-r')
    if rate:
        # convert rate to bits per second
        rate = float(procByte(rate, float, rxBytenumRate, scaleTableMetric))
        if rate==0:
            raise RuntimeError, "Data rate 0 (zero) is not supported"
        # ipd in nano seconds = (mtu*8 / rate) * 1.0e9
        ipd = int( (float(mtu)*8 / rate)*1.0e9 )

    # override time-out value?
    timeOut = get_val('-t')
    if timeOut:
        timeOut = float(timeOut)

    # Extract cornerturning options
    cornerturn = get_val('-ct')
    mode       = get_val('-mode')
    vdif       = get_val('-vdif')
    # Check if we need to do cornerturning 
    if bool(mode)!=bool(vdif):
        raise RuntimeError,"For cornerturning specify at least '-mode' and '-vdif'"
    # we've ascertained both mode/vdif are set or both are None
    do_corner = bool(mode)

    # Split remaining commandline in options and arguments
    (opts, args) = partition(lambda x: re.match("^-", x), sys.argv[1:])

    # require two arguments
    if len(args)!=2:
        usage()
        sys.exit( 1 )

    # UDT requested?
    if '-udt' in opts:
        protocol="udt"

    if '-q' in opts:
        verbose=False

    if '-a' in opts:
        duplicates=True

    # hidden option '-d' - turn on debugging
    if '-d' in opts:
        queries=True

    if verbose:
        print """%s
    copy VLBI data from somewhere to elsewhere
               (c) H. Verkouter
""" % version

    # Note: we've already checked that there's exactly two arguments!
    src = parseURI(args[0], uri_type.SRC)
    dst = parseURI(args[1], uri_type.DST)

    # In case dst addresses localhost and dataIP is not given,
    # we replace the dataIP with the external IP address of this
    # machine [only if there's a unique IP address, that is]
    if (dst.controlIP=="localhost" or dst.controlIP=="127.0.0.1") and dst.dataIP is None:
        dst.dataIP = get_local_ext_ip()
        if dst.dataIP is None:
            allIPs = get_local_ext_ip(False)
            print "*****************************************************"
            print "*                                                   *"
            print "*   It looks like you're copying into this machine  *"
            print "*   but m5copy cannot infer the external IPv4       *"
            print "*   address to use for this machine.                *"
            
            print "*                                                   *"
            print "*   Please specify the external IPv4 address to     *"
            print "*   use in the destination of your transfer, eg:    *"
            print "*                                                   *"
            print "*      m5copy SRC file://192.168.1.4/path/          *"
            print "*      m5copy SRC file://my.host.name/path/         *"
            if allIPs:
                line = "*                                                   *"
                print line
                print "*  Detected external addresses:                     *"
                def p(x):
                    print "*      {0}{1:{2}}*".format( x, "", len(line)-len(x)-8 )
                map(p, allIPs)
            print "*                                                   *"
            print "*****************************************************"
            sys.exit( 1 )

    # IF the '-rt' (realtime) flag is given, only allow that
    # IF the src.media_type is 'IN' or 'MEM'!
    if '-rt' in opts:
        if not (src.mediaType in [media_type.IN, media_type.MEM]):
            raise RuntimeError, "-rt (realtime) flag only supported with source URI of type 'IN' or 'MEM'"
        protocol="udps"

    # absolutely hidden option - allow overwriting of existing data files
    allowOverwrite = '--allow_overwrite' in opts
    if allowOverwrite and dst.mediaType==media_type.FILE:
        if not ('--blame_guifre' in opts):
            print "****************************************************"
            print "*   allow_overwrite requested but you haven't      *"
            print "*   indicated you know what you're doing.          *"
            print "*                                                  *"
            print "*   This option will potentially overwrite         *"
            print "*   existing file(s) at the destination.           *"
            print "*                                                  *"
            print "*   Please add the following command-line flag     *"
            print "*   as well to acknowledge you understand the      *"
            print "*   consequences.                                  *"
            print "*                                                  *"
            print "*     --blame_guifre                               *"
            print "*                                                  *"
            print "*   Thank you for your flying m5copy!              *"
            print "****************************************************"
            sys.exit( 1 )


    # prepare cornerturning - check if all information that's needed is
    # there

    if verbose:
        print src," ===> ",dst
   
    with catcher() as c:
        with xfer_context(src, dst) as xfer:
            xfer()
