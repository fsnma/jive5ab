#!/usr/bin/env python
# Copy data between different machines running jive5a(b(c))
import socket, time, sys, math, copy, itertools, pydoc, re, os, datetime, string, traceback

## Current version
version="$Id$"

## Bastard Python devs. "datetime.timedelta" objects
## only acquired ".total_seconds()" in 2.7
## Do monkey patching of class datetime.timedelta if necessary
def total_seconds(td):
    if hasattr(td, 'total_seconds'):
        return td.total_seconds()
    else:
        return  (td.microseconds + (td.seconds + td.days * 24 * 3600) * 10**6) / 10**6

############################
## Support for 'enums'
##
## X = enum("AAP", "NOOT")
##
## var = X.AAP
##  ...
## if var == X.AAP:
##     ...
############################

class enum(object):
    def __init__(self, *seq):
        self.enums = seq
        for e in self.enums:
            setattr(self, e, e)

    # you can iterate over the enum to find out all defined values
    def __iter__(self):
        class enumiter(object):
            def __init__(self,enuminst):
                self.iterable = enuminst
                self.iter     = iter(enuminst.enums)
            def next(self):
                return getattr(self.iterable, self.iter.next())
        return enumiter(self)

    def __getitem__(self, idx):
        if idx in self.enums:
            return idx
        raise IndexError,"{0} does not exist".format(idx)

## take a list of (pattern, replacement) tuples and run them 
## over the string to produce the final edited string
subber   = lambda acc, (pat, repl): re.sub(pat, repl, acc)
sub      = lambda txt, lst: reduce(subber, lst, txt)

## expands string "1:10,13,20:22" into [1,2,3,4,5,6,7,8,9,10,13,20,21,22]
##   and "5:2" into [5,4,3,2]
##
## Supports arbitrary increments
##    1:10:2 => [1,3,5,7,9]
## Support arithmetic:
##  "2*10:3*10,12-2:12+2"
##  All expressions will be converted to int after evaluating
def expand_string_range(s, rchar=":"):
    rxNum = re.compile(r"^\d+$")
    rxRng = re.compile(r"^(?P<s>[-\d\.+*/%()]+)"+rchar+"(?P<e>[-\d\.+*/%()]+)(:(?P<step>[-+]?\d+))?$")
    def count_from_to(s,e,step):
        while abs(s-e)>=abs(step):
            #print "s:{0} e:{1} diff:{2}".format(s, e, abs(s-e))
            yield s
            s = s + step
        if abs(s-e)<=abs(step):
            yield s
        raise StopIteration
    def mkcounter(item):
        mo = rxRng.match(item)
        if mo:
            # start, end may be expressions
            (s,e) = (int(eval(mo.group('s'))), int(eval(mo.group('e'))))
            defstep = 1 if (s<e) else -1
            step    = mo.group('step')
            step    = int(step) if step else defstep
            # Test if we actually *can* count from start -> end using step:
            # e.g.:    1 -> 10, step -1 isn't going to end very well is it?
            #         -1 -> -10, step 1         ,,           ,,
            # Step size "0" is ONLY allowed if start==end!
            # Also assure ourselves that the step direction and counting
            # direction are identical
            if (not step and (s-e)) or (((e-s) * step )<0):
                raise RuntimeError,"cannot count from {0} to {1} with step {2}".format(s, e, step)
            return count_from_to(s, e, step)
        else:
            mo = rxNum.match(str(eval(item)))
            if not mo:
                raise ValueError, "{0} is not a number! (It's a free man!)".format(item)
            # 'item' may be an expression!
            item = int(eval(item))
            # Note: seems superfluous to return a counter for 1 number but now
            # we have a list of iterables which can easily be transformed into
            # one list via itertools.chain() (see below)
            return count_from_to(item, item, 1)
    return list(itertools.chain(*[mkcounter(x) for x in s.split(",")]))


# given a number + unit, return number between 1.0 and scale +prefix+unit
#  ie.  1024000 "Byte" => "1000 kByte"
def sciprint(num, unit, scale=1000, fmt=".2f"):
    if num<1.0:
        prefixes = ["m", "u", "n", "f", "p", ""] 
        fn       = lambda (n, p), pfx: (n*scale, pfx) if n<1.0 and (n*scale!=n) else (n, p)
    else:
        prefixes = ["k", "M", "G", "T", "P", "E"]
        fn       = lambda (n, p), pfx: (n/scale, pfx) if n>scale else (n, p)
    (n, p) = reduce(fn, prefixes, (float(num), ""))
    return "{0:{n_fmt}} {1}{2}".format(n, p, unit, n_fmt=fmt)



def progress_print(x):
    sys.stdout.write(x)
    sys.stdout.flush()

## A function returning a nice progress update including a bar + percentage, a la scp(1)
def progress(cur, s, e, sz):
    frac = (float(cur - s)/float(e - s)) if e!=s else 0
    pos  = int( frac * sz )
    if pos==0:
        pos = 1
    return "Progress |" + "="*(pos-1) + ">" + " "*(sz-pos)+"| {0:6.2f}%".format(frac*100)


class Progress(object):
    def __init__(self, size):
        self.now       = datetime.datetime.now
        self.size      = size
        self.lastTime  = self.now()
        self.lastCount = 0
        self.maxLen    = 0

    def __call__(self, current, start, end):
        now   = self.now()
        count = (current - start)
        dt    = total_seconds(now - self.lastTime)
        speed = 0.0
        if dt>0:
            speed = (count - self.lastCount) / dt
        txt = progress(current, start, end, self.size)+" "+sciprint(speed, "byte/s", 1024)+" "*10+"\r"
        self.maxLen = max(self.maxLen, len(txt))
        progress_print( txt )
        self.lastTime  = now
        self.lastCount = count

    def say(self, txt):
        self.maxLen = max(self.maxLen, len(txt))
        progress_print( txt + " "*(self.maxLen - len(txt))+"\r" )

    def done(self):
        progress_print(" "*85+"\r")

class DummyProgress(object):
    def __init__(self):
        pass
    def __call__(self, current, start, end):
        pass
    def say(self, txt):
        pass
    def done(self):
        pass

### Sometimes you need a random sequence of 'n' alphanumerical characters
rndChars    = string.letters + string.digits
random_word = lambda n: ''.join(map(lambda x: rndChars[ord(x)%len(rndChars)], os.urandom(n)))
        

############################################################################
## Defaults for the transfer: standard TCP protocol, Mark5 control,data port
############################################################################

mtu         = 1500
ipd         = 0
nthread     = 1
queries     = False
verbose     = True
protocol    = "tcp"
dataport    = 2630
duplicates  = False
controlport = 2620
uri_type    = enum("SRC", "DST")
media_type  = enum("FILE", "DISK", "VBS")
bank_type   = enum("A", "B")
uniqSuffix  = lambda scannum: ".scan." + str(scannum)



def usage():
    pydoc.pager( 
"""
Usage: {progname} [-hvqa] [-udt] [-p <port>] [-m <mtu>] [-r <rate>] SRC DST

Copy VLBI data from SRC to DST. Both SRC and or DST may be located on remote
machines; the default is to address data on the local machine. There is a
possibility to force the data over a different network in case there exists a
different/faster network between the SRC and DST machines than the control
network. Please find examples at the end of the documentation.

    -h        print this message and exit
    -v        print current version and exit
    -q        be quiet, do not display progress (default: {def_verbose})
    -a        allow duplicate scan names on a disk pack to be 
              automatically renamed to <scan>.<scannumber> (default: {def_allow})
    -udt      use UDT as protocol (default: {def_proto})
    -p <port> use this port number for data channel
              (default: {def_data_port})
    -m <mtu>  use this MTU (default: {def_mtu})
              Note: only used when using UDT!
    -r <rate> Limit transmit data rate to <rate> bits per second.
              (default: unlimited - as fast as it will go).
              For your convenience you may use the suffixes 'kMG',
              metric thousands ("x1000"), not binary thousands.
              Note: only effective when using UDT!
    -n <num>  use <num> parallel chunk transfers when doing
              flexbuff => flexbuff transfers (default: {def_nthread})

    SRC, DST: uri-like VLBI data locations. Supported formats:

    mk5://[host][:port][:dataip][/BANK|VSN]/<scan id>
        This addresses a scan on a Mark5 disk pack.

        For SRC uri the <scan id> may be a name number or a comma-
            separated list of numbers or range of numbers: 1-10,13,14.
            The name may contain the wildcard characters '*' or '?' -
            all scan names matching the pattern will be transferred.
            For scan number ranges, the range is inclusive the last number.

        For DST uri the <scan id> will ONLY be interpreted as name;
            we cannot force the scan id number - it depends on what
            is already recorded on the target disk pack. If the name
            happens to be numeric, your scan will be called that.

        The BANK may be provided as "A" or "B" (case insensitive) but is
        optional. If nothing is specified the current active bank on the
        Mark5 will be used.
        
        If something is specified for BANK|VSN and it's not "A" or "B", the
        string will be interpreted as VSN. An error will happen if the given
        VSN cannot be found/switched to on the indicated Mark5.

    file://[host][:port][:dataip]/path/to/(file|dir/)
        Addresses a file or directory on disk (trailing slash means directory).

        In SRC file URIs wildcards '*' and '?' are allowed, provided you're
        running m5copy on the machine itself. Remote wildcards are NOT
        supported. 
        
        SRC file URIs may never address a directory. DST file URIs _MUST_
        name a directory IF the source consists of multiple files/scans.

    vbs://[host][:port][:dataip]/[recording]
        Addresses a vlbi_streamer (vbs) recording on a FlexBuff.
        VBS -> VBS transfers are an 'rsync' operation rather than a
        copy. Therefore some restrictions apply for those transfers.

        In SRC vbs URIs the recording MUST be specified and wildcard
        expansion is only allowed on the local machine.

        On SRC vbs URIs, the "[:dataip]" is not supported. The recording
        name may only be set if the data source is 'mk5://' or 'file://'
        because in VBS -> VBS transfers the name of the recording is
        transferred implicitly; on account of this essentially being an
        rsync operation.

ALL KINDS OF IPv4 ADDRESSES

    The "host" and "port" fields in the URI's are for the CONTROL channel:
    m5copy will send the VSI/S formatted commands to this address.
    
    The "dataip" override field is only allowed in the DST uri. It is
    optional and will override the destination ip/host address (the DST
    control IP) where the data will be sent to.
    
    Typically this option is used to force data over a faster network
    between the SRC and DST machines, bypassing the CONTROL network.

    Note: setting the data port is done using a separate option on the
    command line.

    Defaults are:
        host        localhost/127.0.0.1
        port        {def_ctrl_port}
        dataip      DST::host (i.e. the destination control ip/host)


EXAMPLES

    On a Mark5, copy scan 1-10 from local disk => local file ("disk2file").
    Each scan will end up in "/data/<scanname>.m5a":

        m5copy mk5:///1-10 file:///data/

    Extract scan 200 and rename it:

        m5copy mk5:///200 file:///data/scan200.m5a

    You can force the scans of a specific experiment to be read from a
    specific VSN:

        m5copy mk5:///cmva-007/ek035* file:///data/

    Or from a specific bank:

        m5copy mk5:///B/*ef* file:///data/

    Do a file server => Mark5 copy, forcing data to to a specific VSN,
    "file2net2disk". Each file will become a new scan on the disk pack with
    the name of the file with its extension removed:

        m5copy file:///data/gr* mk5://10.88.0.50/jod+017/

    Do a remote disk2file; i.e. trigger a local disk2file on a Mark5 from
    e.g. your control computer ("remote disk2file"):

        m5copy mk5://10.88.0.50/1-10 file://10.88.0.50/data/

    Push data from a specified VSN loaded in a remote Mark5 to a directory
    on a remote file server. Assume the Mark5 and file server's "control"
    IPv4 addresses are on the 10.88.0.* subnet and there is a high-speed
    data link between the Mark5 and the file server over a different IPv4
    subnet, 192.42.120.*. The file server has IPv4 addresses
    10.88.0.22 (control) and 192.42.120.110 (fat data pipe).

    Using this form of m5copy ensures the data will go over the fast
    192.42.120.* network whilst the control commands are sent over the
    normal network, "disk2net2file". The SRC jive5ab will be told to open
    the data connection to "dataip=192.42.120.110":

        m5copy mk5://10.88.0.50::192.42.120.110/ file://10.88.0.22/data/


""".format(progname=sys.argv[0], def_proto=protocol, def_data_port=dataport, \
           def_ctrl_port=controlport, def_mtu=mtu, def_verbose=verbose, \
           def_nthread=nthread, def_allow=duplicates) )


# One-liner to split a list of things into two lists, one satisfying the predicate, the other not
partition = lambda p, l: reduce(lambda (y,n), x: (y+[x], n) if p(x) else (y, n+[x]), l, ([], []))

######
# Utils
######


# will always resolve to IPv4 address such that 
# user can mix names/ip-addresses and the system will
# still compare them equal (provided they resolve to
# the same IPv4 address, of course)
def resolve_ip(host_or_ip):
    # the socket.getaddrinfo returns a list of 5-element tuples
    # we only want the IPv4 address out of the 5th element ("(ip, port)")
    # and we default to the first returned entry for the host
    try:
        return socket.getaddrinfo(host_or_ip, 0, socket.AF_INET, socket.SOCK_STREAM)[0][4][0]
    except:
        print "Failed to resolve the following name '{0}'".format(host_or_ip)
        raise 


rxBytenumOffset  = re.compile(r"^(?P<sign>\+)?(?P<amount>[0-9]+)(?P<scale>[kMG])?$")
rxBytenumRate    = re.compile(r"^(?P<sign>\+)?(?P<amount>[0-9]+(\.[0-9]*)?|\.[0-9]+)(?P<scale>[kMG])?$")
scaleTableBinary = {'k': 1024, 'M':1024*1024, 'G': 1024*1024*1024}
scaleTableMetric = {'k': 1000, 'M':1000000, 'G': 1000000000}

def procByte(bn, tp, rxBytenum, scaleTable):
    mo = rxBytenum.match(bn)
    if not mo:
        raise RuntimeError, "{0}: invalid byte number".format(bn)
    # passed the regex test, now we can do stuff
    amount = tp(mo.group('amount'))
    scale  = mo.group('scale')
    sign   = mo.group('sign')
    if scale:
        amount *= scaleTable[scale]
    return (sign if sign else '')+str(amount)


class URI(object):
    ## define a static method - the URI factory
    @staticmethod
    def makeURI(src_or_dst, media):
        if src_or_dst==uri_type.SRC:
            return SourceURI(media, src_or_dst)
        elif src_or_dst==uri_type.DST:
            return DestURI(media, src_or_dst)
        else:
            raise ValueError, "Cannot create neither a source or dest URI type"

    def __init__(self, media, src_or_dst):
        self.direction   = src_or_dst
        # who to talk to
        self.controlIP   = None
        self.controlPort = None

        # will be "media_type.FILE" or "media_type.DISK" or "media_type.VBS"
        if not media in media_type:
            raise RuntimeError, "Unrecognized media type '{0}'".format(media)
        self.mediaType   = media

        # contents of path will depend on 
        # media type
        self.path        = None

    def get_direction(self):
        return self.direction

    def __str__(self):
        # do we have these attributes?
        haveSE  = (hasattr(self,'startByte') and hasattr(self, 'endByte'))
        # are any of these not None?
        needSE  = haveSE and (self.startByte or self.endByte)
        # then we possibly need to tag them on
        seBytes = (":"+ (self.startByte if self.startByte else "") + ":" + (self.endByte if self.endByte else "")) if needSE else ''
        return "{0}::{1} [{2}:{3}{4}] {5}{6}{7}".format(self.direction, self.mediaType, self.controlIP, self.controlPort, \
                                                (":"+(self.dataIP if self.dataIP else "<controlIP>") if hasattr(self,'dataIP') else ""), \
                                                ((self.bank+"/" if self.bank else "") if hasattr(self, 'bank') else ""), self.path, \
                                                seBytes)

    def parseStartEndByte(self, sb, eb):
        # if any of the start/end bytes are set and we
        # do not have one of the attributes ... 
        if (sb or eb) and not (hasattr(self, 'startByte') and hasattr(self, 'endByte')):
            raise RuntimeError, "{0} does not support configuring start and/or end byte number".format(str(self))

        if sb: 
            self.startByte = procByte(sb, int, rxBytenumOffset, scaleTableBinary)
        
        if eb:
            self.endByte = procByte(eb, int, rxBytenumOffset, scaleTableBinary)

class SourceURI(URI):
    def __init__(self, media, src_or_dst):
        super(SourceURI, self).__init__(media, src_or_dst)

        # Some URIs support start, end byte
        # These will be *functions* which both will be 
        # passed the current start and end byte of the scan
        # being processed such they can do the appropriate offset
        # magic (eg negative numbers work from the end etc),
        # but always only on data source(s)
        self.startByte   = None
        self.endByte     = None

        if self.mediaType==media_type.DISK:
            self.bank    = None
            self.VSN     = None



class DestURI(URI):
    def __init__(self, media, src_or_dst):
        super(DestURI, self).__init__(media, src_or_dst)
        self.dataIP      = None

        if self.mediaType==media_type.DISK:
            self.bank    = None
            self.VSN     = None


rxDisk = re.compile(r"^mk5:")
rxFile = re.compile(r"^file:")
rxVBS  = re.compile(r"^vbs:")

## For URI parsing we must know if we're parsing source or destination
## URI's. 'src_or_dst' is an 'enum' (see below)
def parseURI(uri, src_or_dst):
    if rxDisk.match(uri):
        return parseDisk(uri, src_or_dst)
    elif rxFile.match(uri):
        return parseFile(uri, src_or_dst )
    elif rxVBS.match(uri):
        return parseVBS(uri, src_or_dst )
    else:
        raise ValueError, "Unrecognized URI '{0}'".format(uri)


## Not loosely modelled after jive5ab's OPTARG macro, honestly .... ;-)
def OPTARG(lst, n, default=None):
    try:
        return lst[n] if len(lst[n]) else default
    except IndexError:
        return default


# supported:
#  mk5://[host][:port][:dataip]/[BANK|VSN/]<scanname:scanids>[:[<start>][:<end>|+<amount>]]
# So, before the first "/" is all kind of host/ip/port crap.
# note that "[:dataip]" is only supported on source URIs
def parseDisk(uri_org, src_or_dst):
    uri = re.sub("^mk5:", "", uri_org)
    rv = URI.makeURI(src_or_dst, media_type.DISK)

    # the host/port/dataip is between the leading double slash and the third
    # slash
    mo = re.match(r"^//([^/]*)/", uri)
    if not mo:
        raise RuntimeError, "{0}: invalid - does not match //.../".format(uri_org)
    hoststuff = mo.group(1)

    # now that we have matched the hoststuff out of it, we can take it out
    # of the URI
    path = re.sub(r"^//[^/]*/", "", uri)

    # any slashes remaining in the path means that a bank/vsn was passed
    slashed = path.split("/")
    if len(slashed)>2:
        raise RuntimeError, "{0}: invalid - too many slashes in bank/scan part".format(uri_org)

    # the last part is always the scanid/number
    # On a source disk, we MUST have a scan name, on DST it *may* be a scan name
    b, p = (None, None)
    if len(slashed)==2:
        (b, p) = slashed
    else:
        p = path

    # Did anyone mention start/end byte?
    p_split = p.split(':')
    rv.path = p_split[0]  # path is always the first bit

    if rv.direction==uri_type.SRC:
        if not rv.path:
            raise RuntimeError, "{0}: source URI MUST have a scan name/id".format(uri_org)

    # if there's a leading part, it's the bank/vsn
    if b:
        b = b.upper()
        if not b in bank_type:
            # must be VSN then
            if hasattr(rv, 'VSN'):
                rv.VSN = b
            else:
                raise RuntimeError, "{0}: media type {1} does not support setting VSN to {2}".format(uri_org, rv.mediaType, b)
        else:
            if hasattr(rv, 'bank'):
                rv.bank = b
            else:
                raise RuntimeError, "{0}: media type {1} does not support setting bank to {2}".format(uri_org, rv.mediaType, b)

    # Now parse the host/port stuff
    colonized = hoststuff.split(':')

    # Length check - at most three entries
    if len(colonized)>3:
        raise RuntimeError, "{0}: invalid 'host:port:dataip' part".format(uri_org)

    # Because we have the ":"'s separating the entries we only need to
    # verify if they exist at all
    rv.controlIP   = resolve_ip(OPTARG(colonized, 0, "localhost"))
    rv.controlPort = OPTARG(colonized, 1, controlport)
    if rv.controlPort:
        rv.controlPort = int(rv.controlPort)

    # Only source-type URI's parse the data ip;
    # so we only set the value if the URI object _has_ that
    # attribute
    dataip = OPTARG(colonized, 2)
    if dataip:
        if hasattr(rv, 'dataIP'):
            rv.dataIP = resolve_ip(dataip)
        else:
            raise RuntimeError, "{0} does support setting of dataip ({1})".format(uri_org, src_or_dst)

    # Save the start/end byte number parsing for last such that the URI is filled in
    rv.parseStartEndByte( OPTARG(p_split, 1), OPTARG(p_split, 2) )
    return rv


## Supported:  (the leading "file:" has already been stripped)
##  file://[host][:port][:dataip]/path/to/file[:[<start>][:<end>|+<amount>]]
# note that "[:dataip]" is only supported on source URIs
def parseFile(uri_org, src_or_dst):
    uri = re.sub("^file:", "", uri_org)
    rv = URI.makeURI(src_or_dst, media_type.FILE)

    # the host/port/dataip is between the leading double slash and the third
    # slash
    mo = re.match(r"//([^/]*)/", uri)
    if not mo:
        raise RuntimeError, "{0}: invalid - does not match //.../".format(uri_org)
    hoststuff = mo.group(1)

    # now that we have matched the hoststuff out of it, we can take it out
    # of the URI
    p = re.sub(r"^//[^/]*", "", uri)

    # Did anyone mention start/end byte?
    p_split = p.split(':')
    rv.path = p_split[0]  # path is always the first bit - start/end is last (below)

    # On source file name we MUST have a filename
    if rv.direction==uri_type.SRC:
        if len(rv.path)<=1:
            raise RuntimeError, "{0}: source URI MUST have a file/path".format(uri_org)

    # Now parse the host/port stuff
    colonized = hoststuff.split(':')

    # Length check - at most three entries
    if len(colonized)>3:
        raise RuntimeError, "{0}: invalid 'host:port:dataip' part".format(uri_org)

    # Because we have the ":"'s separating the entries we only need to
    # verify if they exist at all
    rv.controlIP   = resolve_ip(OPTARG(colonized, 0, "localhost"))
    rv.controlPort = OPTARG(colonized, 1, controlport)
    if rv.controlPort:
        rv.controlPort = int(rv.controlPort)

    # Only source-type URI's parse the data ip;
    # so we only set the value if the URI object _has_ that
    # attribute
    dataip = OPTARG(colonized, 2)
    if dataip:
        if hasattr(rv, 'dataIP'):
            rv.dataIP = resolve_ip(dataip)
        else:
            raise RuntimeError, "{0} does support setting of dataip ({1})".format(uri_org, src_or_dst)

    # Save the start/end byte number parsing for last such that the URI is filled in
    rv.parseStartEndByte( OPTARG(p_split, 1), OPTARG(p_split, 2) )
    return rv

# 'vbs' is a vlbi-streamer recording on a flexbuff
#  at the moment this one does *not* support 'slicing', i.e.
#  no start/end byte specification
#
#   vbs://[host][:port][:dataip]/recording
#
# note that "[:dataip]" is only supported on source URIs
def parseVBS(uri_org, src_or_dst):
    uri = re.sub("^vbs:", "", uri_org)
    rv = URI.makeURI(src_or_dst, media_type.VBS)

    # the host/port/dataip is between the leading double slash and the third
    # slash
    mo = re.match(r"//([^/]*)/", uri)
    if not mo:
        raise RuntimeError, "{0}: invalid - does not match //.../".format(uri_org)
    hoststuff = mo.group(1)

    # now that we have matched the hoststuff out of it, we can take it out
    # of the URI
    rv.path = re.sub(r"^//[^/]*/", "", uri)

    # Did anyone mention start/end byte?
    # we do parse them so we can yell if we find 'm :D
    if rv.path.count(':'):
        raise RuntimeError, "{0}: VBS recordings do not support start/end byte".format(uri_org)

    # On source vbs we MUST have a recording name
    if rv.direction==uri_type.SRC:
        if not rv.path:
            raise RuntimeError, "{0}: source URI MUST have a recording name".format(uri_org)

    if rv.path.count('/'):
        raise RuntimeError, "{0}: recording name may not contain slashes".format(uri_org)

    # Now parse the host/port stuff
    colonized = hoststuff.split(':')

    # Length check - at most three entries
    if len(colonized)>3:
        raise RuntimeError, "{0}: invalid 'host:port:dataip' part".format(uri_org)

    # Because we have the ":"'s separating the entries we only need to
    # verify if they exist at all
    rv.controlIP   = resolve_ip(OPTARG(colonized, 0, "localhost"))
    rv.controlPort = OPTARG(colonized, 1, controlport)
    if rv.controlPort:
        rv.controlPort = int(rv.controlPort)

    # Only source-type URI's parse the data ip;
    # so we only set the value if the URI object _has_ that
    # attribute
    dataip = OPTARG(colonized, 2)
    if dataip:
        if hasattr(rv, 'dataIP'):
            rv.dataIP = resolve_ip(dataip)
        else:
            raise RuntimeError, "{0} does support setting of dataip ({1})".format(uri_org, src_or_dst)
    return rv



###########################
# VSI-S command/reply stuff
###########################

def split_reply(reply):
    end_index = reply.rfind(';')
    if end_index != -1:
        reply = reply[:end_index]
    separator_index = reply.find('=')
    if separator_index == -1:
        separator_index = reply.find('?')
        if separator_index == -1:
            return [reply]

    return map(lambda x: x.strip(), [reply[0:separator_index]] + reply[separator_index+1:].split(':'))

## Facilitate communication with a Mark5
class Mark5(object):
    anyReturn = range(0,9)

    def __init__(self, address, port, timeout=5):
        self.timeout       = timeout
        self.connect_point = (address, port)
        self.socket        = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        self.socket.settimeout(self.timeout)
        try:
            self.socket.connect(self.connect_point)
        except:
            raise RuntimeError, "Failed to connect to {0}".format(self.connect_point)
   
    def get_type(self):
        return self.send_query("dts_id?")[2]

    def get_program(self):
        # this query should only return "0", not even "1"!
        return self.send_query("version?", [0])[2]

    def send_query(self, query, acceptable_codes=[0,1], timeout=None):
        if queries:
            print datetime.datetime.now(),self.connect_point,"Qry:",query
        if timeout and timeout!=self.timeout:
            self.socket.settimeout(timeout)
        self.socket.send(query + "\n\r")
        orgreply = self.socket.recv(1024).strip()
        if queries:
            print datetime.datetime.now(),self.connect_point,"Reply:",orgreply
        reply = split_reply(orgreply)
        self.socket.settimeout(self.timeout)
        if not int(reply[1]) in acceptable_codes:
            raise RuntimeError, "Unacceptable return code {0} from query '{1}' - {2}".format(int(reply[1]), query, orgreply)
        return reply

    def location(self):
        return ":".join(map(str, self.connect_point))

    ## attempt to switch to bank 'bank' on the Mark5
    ## indicated by 'ctrl', assumed to be a 'Mark5' object
    def switch_bank(self, bank):
        bank    = bank.upper()
        actbank = self.send_query("bank_info?")[2].upper()
        if actbank!=bank:
            # issue the bank switch command
            reply = self.send_query("bank_set={0}".format(bank), [1])
            # wait for it to complete
            while True:
                time.sleep(1)
                reply = self.send_query("bank_set?", [0, 6])
                if reply[1]=="0":
                    break
            # verify it's a different bank than we started with
            if actbank==reply[2].upper():
                reply = self.send_query("error?")
                raise RuntimeError, "{0} could not switch to bank {1} [{2}]".format(self.location(), bank, ":".join(reply[3:]))
        return actbank

    # Attempt to switch to the bank containing the indicated VSN
    def switch_vsn(self, vsn):
        vsn = vsn.upper()

        # query which VSNs are currently loaded
        #  0          1   2       3         4       5
        #  !bank_set? 0 : [AB-] : <vsn>|- : [BA-] : <vsn>|- ;
        # Create a mapping of VSN => bank
        reply = self.send_query("bank_set?", [0])
        def proc_entry(acc, idx):
            # extract [<bank>, <vsn>]
            sel = reply[idx:idx+2]
            # if bank or vsn == '-': 
            #     'inactive bank' or 'no module loaded'
            if not "-" in sel:
                # Note: <vsn> is typically  <vsn>/<capacity>/<speed>
                acc[ sel[1].upper().split('/')[0] ] = sel[0].upper()
            return acc
        vsnbankmap = reduce(proc_entry, [2,4], {})
        if not vsn in vsnbankmap:
            raise RuntimeError, "{0} VSN {1} not found on this machine".format(self.location(), vsn)
        return self.switch_bank(vsnbankmap[vsn])

# default configuration for jive5ab for m5copy - separate it from direct
# Mark5 control class
class Jive5AB(Mark5):
    def __init__(self, address, port, timeout=5, runtime=None, bs="2M"):
        super(Jive5AB, self).__init__(address, port, timeout)

        # do we have jive5* running on that connection?
        self.program = self.get_program()
        if not re.search("^jive5", self.program):
            raise RuntimeError, "{0}:{1} is not running a version of jive5a(b(c))".format(address, port)

        # Save the values of things that we're going to overwrite
        # Note: we set the ipd on both ends, even though it is
        #       only useful for the sender, and then only when UDT
        #       is used
        self.runtime    = copy.deepcopy(runtime)
        self.oldRuntime = None
        self.prevState  = {}

        # If we're going to create a new runtime there's no
        # point in saving the state anyway ....
        if self.runtime:
            self.oldRuntime = self.send_query("runtime?", [0])[2]
            self.send_query("runtime={0}:new".format(runtime), [0])
        else:
            self.save( ["net_protocol", "mtu", "ipd", "net_port"] )

        self.send_query("mode=none", [0])
        self.send_query("net_protocol={0:s}:64M:{1:2}".format(protocol, bs), [0])
        self.send_query("mtu={0:d}".format(mtu), [0])
        self.send_query("ipd={0}ns".format(ipd))
        self.send_query("net_port={0:d}".format(dataport), [0])

    def save(self, cmdlist):
        self.prevState = dict(zip(cmdlist, map(lambda x: self.send_query(x+"?", [0]), cmdlist)))

    def restore(self):
        for (k,v) in self.prevState.iteritems():
            self.send_query(k+"="+":".join(v[2:]))
        if self.oldRuntime:
            self.send_query("runtime={0}:delete".format(self.runtime))
            self.send_query("runtime={0}".format(self.oldRuntime))


####################################################################
##
##  The model is:
##    a Source or Dest URI is passed to a DataSource or DataSink
##    the DataSource yields Scans to be transferred
##    Depending on the actual transfer a Source and Dest XFER
##    are created such that we can easily couple different
##    sources and destinations
##
####################################################################

class Scan(object):
    # no 'constructor', the only interesting bit is the interface
    # I know that in Python we could use 'duck typing' such that
    # the different objects only need to adhere to the same interface
    # but in my book that's called inheritance :D
    def name(self):
        raise RuntimeError,"Not implemented"

class DiskScan(Scan):
    def __init__(self, (num, name), **kwargs):
        self.scanId = (num, name)
        # set optianal extra attribute(s)
        self.__dict__.update( kwargs )

    def name( self ):
        return self.scanId[1]

class FileScan(Scan):
    def __init__(self, name):
        self.scanId = name

    def name( self ):
        return self.scanId


#####################################################################
##
## base classes for a xfer
##
##  DataSources must allow iteration over themselves; each iteration
##    step should yield the name of a transferrable unit. So even if
##    the URI addressed only a single unit, it should iterator over
##    a list of length one.
##
##  DataSinks:
## 
##    * must support computing an output name, given an input
##    name. Each data sink must be able to tell wether it allows
##    multiple names to be computed. E.g. the FileDest only allows
##    computation of multiple names IF it addresses a directory. If a 
##    specific name was given "/dir/file[.ext]" then obviously it
##    cannot compute >1 name. 
##    For the DiskDest this is similar; if an output scan name was
##    explicitly given, no more scan names can be computed
##
##    * must be able to tell wether they can compute multiple output
##    names such that the s/w can verify if the user has made an error
##    by specifying >1 input transferrable units and one specific output
##    name
##
##    * must be able to tell the dataIP to which the data must be sent
##
#####################################################################


class DataSource(Jive5AB):
    def __init__(self, src, runtime=None):
        self.source  = src
        super(DataSource, self).__init__(self.source.controlIP, self.source.controlPort, runtime=runtime)

    # must return a list of source paths
    def __iter__(self):
        raise RuntimeError, "Someone forgot to implement this one"
    def __next__(self):
        raise RuntimeError, "Someone forgot to implement this one"

    def cleanup(self):
        raise RuntimeError, "Someone forgot to implement this one"

    def startByte(self):
        return self.source.startByte

    def endByte(self):
        return self.source.endByte

    def location(self):
        return self.source.controlIP+"::"

class DataSink(Jive5AB):
    def __init__(self, dst, runtime=None):
        self.destination = dst
        super(DataSink, self).__init__(self.destination.controlIP, self.destination.controlPort, runtime=runtime)

    # Is the DataSink configured to support >1 output names?
    def multiple_outputs(self):
        raise RuntimeError, "Someone forgot to implement this one!"

    # Compute the output name of the given input
    def compute_outputname(self, input):
        raise RuntimeError, "Someone forgot to implement this one!"

    def cleanup(self):
        raise RuntimeError, "Someone forgot to implement this one"

    def dataIP(self):
        DST = self.destination
        return DST.dataIP if hasattr(DST, 'dataIP') and not DST.dataIP is None else DST.controlIP

    def location(self):
        return self.destination.controlIP+"::"

#########################################
##
##   Concrete derivatives of 
##        the base classes 
##
##########################################


#################### the sources ############################

## Mark5 disk pack as source
class DiskSource(DataSource):
    def __init__(self, location):
        super(DiskSource, self).__init__(location)

        SRC  = self.source

        # Select the requested bank or VSN, if one was given.
        # Note: bank and VSN are mutually exclusive at most one
        #       of them is actually set
        if SRC.bank:
            self.switch_bank(SRC.bank)
        if SRC.VSN:
            self.switch_vsn(SRC.VSN)

        # Look at the location - if it's made out of numbers, dashes and commas
        # it's a list of scan numbers, otherwise a scan name(s)
        rxNums = re.compile(r"^([0-9]+(-[0-9]+)?)(,([0-9]+(-[0-9]+)?))*$")

        filter_f = None
        if SRC.path=="*":
            # Short circuit for all scans
            filter_f = lambda x : True
        elif rxNums.match(SRC.path):
            scanids = set(expand_string_range(SRC.path, '-'))
            filter_f = lambda (num, name): num in scanids
        else:
            # replace "*" by ".*" and "?" by "."
            path     = sub(SRC.path, [("\.","\."), ("\*", ".*"), ("\+", "\+"), ("\?",".")])
            scanname = re.compile(r"^"+path+"$")
            filter_f = lambda (num, name): scanname.match(name)

        # Get the list of scans and immediately filter them
        nscan    = int(self.send_query("dir_info?", [0])[2])

        def get_scan(i):
            self.send_query("scan_set={0:d}".format(i), [0])
            r = self.send_query("scan_set?", [0])
            if int(r[2])!=i:
                raise RuntimeError, "Scan {0} failed to set".format(i)
            return (i, r[3])

        self.scanList = map(lambda x: DiskScan(x), \
                            filter(filter_f, map(get_scan, xrange(1, nscan+1))))

        # Check for duplicate names - if there are, either fix them or
        # fail with an error + hint as to what the user should do to fix
        # this
        names = set(map(lambda x: x.name(), self.scanList))
        if len(names)<len(self.scanList):
            # uh-oh. duplicate names!
            if not duplicates:
                raise RuntimeError, "Duplicate scan names found in your scan " + \
                                    "selection. Re-run with '-a' flag " + \
                                    "(see help) to have m5copy rename them " + \
                                    "on the output"
            # Step 1. figure out the names of the scans that have duplicates
            def countert(acc, scan):
                acc.update({scan.name(): acc.setdefault(scan.name(), 0)+1})
                return acc
            dupnames = map(lambda (k, v): k, filter(lambda (k,v): v>1, reduce(countert, self.scanList, {}).iteritems()))
            # Step 2. rename scans that have duplicate names
            def renamert( diskscan ):
                (num, name) = diskscan.scanId
                if name in dupnames:
                    return DiskScan( (num, name+uniqSuffix(num)), duplicate=True )
                else:
                    return diskscan
            self.scanList = map(renamert, self.scanList)

    # implement the DataSource part
    def __iter__(self):
        return iter(self.scanList)

    def __len__(self):
        return len(self.scanList)

    def location(self):
        SRC = self.source
        return super(DiskSource, self).location() + (SRC.bank+"/" if SRC.bank else (SRC.VSN+"/" if SRC.VSN else ""))

    def cleanup(self):
        self.restore()


class FileSource(DataSource):
    def __init__(self, location):
        # file transfers are done in a different runtime
        super(FileSource, self).__init__(location, runtime=random_word(8))

        # we cannot retrieve the list of files remotely
        # but only locally
        SRC  = self.source
        self.pathList         = [SRC.path]
        (self.dir, self.file) = os.path.split(SRC.path)

        # do we need to do wildcard processing?
        if '*' in SRC.path or '?' in SRC.path:
            if SRC.controlIP != '127.0.0.1':
                raise RuntimeError, "Unfortunately we do not support wildcards in file names on remote systems"
            # Check if path contains wildcards. Only allow those
            # in the file name part
            (dir, file) = os.path.split( SRC.path )
            if '*' in dir or '?' in dir:
                raise RuntimeError, "Wildcards not allowed in directory names"
            # we now know that the wildcard, if present, must reside in the file part
            # replace "*" by ".*" and "?" by "." in the file name
            # (also escape regex special chars)
            file     = sub(file, [("\.", "\."), ("\*", ".*"), ("\+", "\+"), ("\?",".")])
            filename = re.compile(r"^"+file+"$")
            # Only consider files located in 'dir'
            self.pathList = []
            for (root, dirs, files) in os.walk(dir):
                if root!=dir:
                    dirs = []
                    continue
                # use the reduce structure such that we do not _overwrite_ self.pathList
                # but append to it
                self.pathList = reduce( \
                    lambda acc, p: acc+[os.path.join(root,p)] if filename.match(p) else acc, \
                    files, self.pathList )

        self.pathList = map(lambda x: FileScan(x), self.pathList)

    def __iter__(self):
        return iter(self.pathList)

    def __len__(self):
        return len(self.pathList)

    def location(self):
        return super(FileSource, self).location()

    def cleanup(self):
        self.restore()


class VBSSource(DataSource):
    def __init__(self, location):
        # We can support >1 vbs synchronization / FlexBuff
        # by doing it in multiple runtimes
        super(VBSSource, self).__init__(location, runtime=random_word(8))

        SRC  = self.source
        self.pathList = [SRC.path]

        # do we need to do wildcard processing?
        if '*' in SRC.path or '?' in SRC.path:
            if SRC.controlIP != '127.0.0.1':
                raise RuntimeError, "Unfortunately we do not support wildcards in file names on remote systems"
            # Note: the parseVBS has already guaranteed that the path
            # contains no slashes. Do regex special char escaping as well
            # as translating "*" into ".*" and "?" into "."
            path     = copy.copy(SRC.path)
            path     = sub(path, [("\.", "\."), ("\*", ".*"), ("\+", "\+"), ("\?",".")])
            rxRecord = re.compile(r"^"+path+"$")
            rxDisk   = re.compile(r"^disk[0-9]+$")
            rxRecDir = re.compile(r"^/mnt/disk[0-9]+$")
            rxPath   = re.compile(r"^/mnt/disk[0-9]+/(?P<recording>"+path+")$")
            rxFile   = re.compile(r"^"+path+"\.[0-9]{8}$")

            # On the FlexBuff all recordings reside under 
            # /mnt/disk[0-9]+/<recording>
            # Maybe we should filter out only the recordings (1) matching
            # the pattern (d'oh) but also those that actually contain
            # *data*!
            # vlbi_streamer data files are found:
            #   /mnt/disk[0-9]+/<recording>/<recording>.[0-9]{8} 
            #  i.e. files with basename <recording> and an 8-digit sequence
            #  number
            recordingset  = set()
            for (root, dirs, files) in os.walk("/mnt"):
                # in "/mnt" we only consider the "dirs" that match the
                # "disk[0-9]+"
                if root=="/mnt":
                    dirs = filter(lambda x: rxDisk.match(x), dirs)
                    continue
                # In <root>'s matching "/mnt/disk[0-9]+", we only 
                # consider "dirs" that match the recording
                if rxRecDir.match(root):
                    dirs = filter(lambda x: rxRecord.match(x), dirs)
                    continue
                # In <root>'s actually matching
                # /mnt/disk[0-]+/<recording>/ we look for
                # files matching "<recording>.[0-9]{8}"
                mo = rxPath.match(root)
                if mo:
                    # if we find any files matching, the recording
                    # can be added
                    if len(filter(lambda x: rxFile.match(x), files)):
                        recordingset.add( mo.group('recording') )
            self.pathList = list(recordingset)
        self.pathList = map(lambda x: FileScan(x), self.pathList)

    def __iter__(self):
        return iter(self.pathList)

    def __len__(self):
        return len(self.pathList)

    def location(self):
        return super(VBSSource, self).location()

    def cleanup(self):
        self.restore()

#################### the destinations ############################

class FileDest(DataSink):
    def __init__(self, location):
        # Do the transfer in a different runtime
        super(FileDest, self).__init__(location, runtime=random_word(8))
        
        # Split the destination into path/file
        DST                   = self.destination
        (self.dir, self.file) = os.path.split(DST.path)

    def location(self):
        return super(FileDest, self).location()

    # Is the DataSink configured to support >1 output names?
    def multiple_outputs(self):
        # Yes we are if the "self.file" part is null/empty
        return not self.file

    # Compute the output name of the given input.

    # If we were constructed with an explicit file as path, then we return
    # the path we were created with, otherwise the concatenation of self.dir
    # + the input name. Append extension ".m5a" if necessary
    def compute_outputname(self, input):
        if self.file:
            return self.destination.path
        else:
            # have to split input into path/file before appending to *our* dir
            (_dir, file) = os.path.split(input.name())
            # check if the the input has an extension. If not, append it
            (base, ext)  = os.path.splitext(file)
            if not ext:
                ext = ".m5a"
            return os.path.join(self.dir, base+ext)

    def cleanup(self):
        self.restore()

class DiskDest(DataSink):
    def __init__(self, location):
        super(DiskDest, self).__init__(location)

        DST  = self.destination

        # Select the requested bank or VSN, if one was given.
        # Note: bank and VSN are mutually exclusive at most one
        #       of them is actually set
        if DST.bank:
            self.switch_bank(DST.bank)
        if DST.VSN:
            self.switch_vsn(DST.VSN)

    def location(self):
        DST = self.destination
        return super(DiskDest, self).location() + (DST.bank+"/" if DST.bank else (DST.VSN+"/" if DST.VSN else ""))

    # Is the DataSink configured to support >1 output names?
    def multiple_outputs(self):
        # Yes we are if no specific scan (==path) was configured when we
        # were created
        return not self.destination.path

    # Compute the output name of the given input.

    # If we were constructed with an explicit path, then we return the path
    # we were created with, otherwise it will be the basename of the input
    # with extension removed.
    # This means it works for "/full/path/to/file.m5a" as well as "gr036_ef_no0001"
    def compute_outputname(self, input):
        if self.destination.path:
            return self.destination.path
        else:
            # ok, first split into (dir, file)
            (_dir, file) = os.path.split(input.name())
            # strip extension
            return os.path.splitext(file)[0]

    def cleanup(self):
        self.restore()

class VBSDest(DataSink):
    def __init__(self, location):
        # Do the transfer in a different runtime
        super(VBSDest, self).__init__(location, runtime=random_word(8))

    def location(self):
        return super(VBSDest, self).location()

    # Is the DataSink configured to support >1 output names?
    def multiple_outputs(self):
        # Yes we are if no specific scan (==path) was configured when we
        # were created OR if the path was '/dev/null'!
        return not self.destination.path or self.destination.path=='/dev/null'

    # Compute the output name of the given input.

    # If we were constructed with an explicit path, then we return the path
    # we were created with, otherwise it will be the basename of the input
    # with extension removed.
    # This means it works for "/full/path/to/file.m5a" as well as "gr036_ef_no0001"
    def compute_outputname(self, input):
        if self.destination.path:
            return self.destination.path
        else:
            # ok, first split into (dir, file)
            (_dir, file) = os.path.split(input.name())
            # strip extension
            return os.path.splitext(file)[0]

    def cleanup(self):
        self.restore()


#####################################################################################
##
##
##                  The actual transfers
##
##
#####################################################################################


class SourceXFER(object):
    # interface for source xfers
    def __init__(self, source):
        self.DataSource = source

    # start transferring data from scan 'scan' to the destination 'dataip'
    def start(self, scan, dataip):
        raise RuntimeError, "Someone forgot to implement this one"

    # return tuple with (start, current, end) if xfer still running,
    # None if transfer is finished
    def progress(self):
        raise RuntimeError, "Someone forgot to implement this one"

    # must be cancellable
    def cancel(self):
        raise RuntimeError, "Someone forgot to implement this one"

class DestXFER(object):
    def __init__(self, sink):
        self.DataSink = sink

    # open output for accepting output into 'output'
    def open(self, output):
        raise RuntimeError, "Someone forgot to implement this one"

    # return received byte count. Typically the transfer will
    # wait until this number has stabilized, so be sure to return
    # the same number if the transfer is inactive or has finished
    # (in case you can tell)
    def rcv_bytecount(self):
        raise RuntimeError, "Someone forgot to implement this one"

    # must be cancellable
    def cancel(self):
        raise RuntimeError, "Someone forgot to implement this one"


####### Actual concrete transfers

# A disk2file is both ... we must introduce a class variable
# to let the destination part and source path communicate with
# each other
class disk2file(SourceXFER, DestXFER):
    outputFileName = None

    def __init__(self, src_or_dst):
        # look at what flavour we were initialized with to decide
        # which of our base classes should be initialized
        if isinstance(src_or_dst, DataSource):
            self.isSource = True
            SourceXFER.__init__(self, src_or_dst)
        else:
            self.isSource = False
            DestXFER.__init__(self, src_or_dst)

    #### Both types (SourceXFER and DestXFER) should be 
    #### cancellable
    def cancel(self):
        if self.isSource:
            self.DataSource.send_query("reset=abort", Mark5.anyReturn)
        else:
            disk2file.outputFileName = None

    #### This is the SourceXFER part of the transfer
    def start(self, scan, dataip):
        # shorthand to the control interface
        CTRL = self.DataSource

        # disk2file transfer is always coming from a DiskSource
        # (in case it isn't this is an error) so the "scanIds" that
        # are passed into us are really tuples, "(scan number, scan name)"
        (scanNum, scanName) = scan.scanId

        startByte = CTRL.startByte()
        endByte   = CTRL.endByte()

        # Attempt to set the correct scan and verify it did set.
        CTRL.send_query("scan_set={0:d}".format(scanNum), [0])
        reply = CTRL.send_query("scan_set?", [0])
        # If the current disk scan was marked as duplicate, it means
        # that some unique suffix has been appended. We must strip
        # that name to do our consistency checking
        if hasattr(scan, 'duplicate'):
            suffix = uniqSuffix(scanNum)
            if scanName.endswith(suffix):
                # Ok, modify scan name
                # Find the right-most uniqSuffix(). Suppose that by chance
                # the scan with name "name.scan.2" would end up in scan
                # postions #1 and  #2 (duplicated) on the disk pack.
                # then the 2nd uniquefied scan name would be:
                #    "name.scan.2.scan.2"
                # if we then do string.sub(".scan.2", "") it would replace 
                # *both* instances instead of only the last one
                # making our test for the scan's existence on the disk pack
                # fail!
                sidx = scanName.rfind(suffix)
                if sidx<0:
                    raise RuntimeError, "Could not find unique suffix whilst it should be there?!"
                scanName = scanName[0:sidx]
            else:
                raise RuntimeError, \
                        "Scan #{0} ({1}) was marked as duplicate but does not end with expected suffix '{2}'".format( \
                            scanNum, scanName, suffix)
        if not (int(reply[2])==scanNum and reply[3]==scanName):
            raise RuntimeError, "Scan #{0} ({1}) is not that anymore, it is now #{2} ({3})".format( \
                                 scanNum, scanName, int(reply[2]), reply[3])

        CTRL.send_query("disk2file={0}:{1}:{2}:{3}".format( disk2file.outputFileName, \
                startByte if startByte else "", endByte if endByte else "", \
                'w' if disk2file.outputFileName=="/dev/null" else 'n'), [1])

    def progress(self):
        r = self.DataSource.send_query("disk2file?")
        return None if r[2]=="inactive" else (int(r[5]), int(r[4]), int(r[6]))

    #### This is the DestXFER part of the interface
    
    # The "open()" method in this local xfer stores the output file name
    def open(self, output):
        disk2file.outputFileName = output

    def rcv_bytecount(self):
        return 0


        
# file2disk is, like disk2file, both
class file2disk(SourceXFER, DestXFER):
    outputScanName = None
    inputRuntime   = None

    def __init__(self, src_or_dst):
        # look at what flavour we were initialized with to decide
        # which of our base classes should be initialized
        if isinstance(src_or_dst, DataSource):
            self.isSource = True
            SourceXFER.__init__(self, src_or_dst)
            # we must change from arbitrary runtime to
            # runtime
            r = self.DataSource.send_query("runtime?", [0])
            file2disk.inputRuntime = r[2]
            self.DataSource.send_query("runtime=0", [0])
        else:
            self.isSource = False
            DestXFER.__init__(self, src_or_dst)

    #### Both types (SourceXFER and DestXFER) should be 
    #### cancellable
    def cancel(self):
        if self.isSource:
            self.DataSource.send_query("reset=abort", Mark5.anyReturn)
            self.DataSource.send_query("runtime={0}".format(file2disk.inputRuntime), [0])
            file2disk.inputRuntime = None
        else:
            file2disk.outputFileName = None

    #### This is the SourceXFER part of the transfer
    def start(self, scan, dataip):
        CTRL = self.DataSource
        startByte = CTRL.startByte()
        endByte   = CTRL.endByte()
        CTRL.send_query("file2disk={0}:{1}:{2}:{3}".format(scan.name(), \
                (startByte if startByte else ""), (endByte if endByte else ""), \
                            file2disk.outputScanName), [1])

    def progress(self):
        r = self.DataSource.send_query("file2disk?")
        return None if r[2]=="inactive" else (int(r[5]), int(r[4]), int(r[6]))

    #### This is the DestXFER part of the interface

    # The "open()" method in this local xfer creates the 
    # function that will run the actual command, apart from
    # two arguments the ".start()" will supply - the input
    # file name and the actual control interface
    def open(self, outputScanName):
        file2disk.outputScanName = outputScanName

    def rcv_bytecount(self):
        return 0


## disk2net

class disk2net(SourceXFER):
    def __init__(self, datasource):
        super(disk2net, self).__init__( datasource )

    def start(self, scan, dataip):
        # shorthand to the control interface
        CTRL = self.DataSource

        # disk2net transfer is always coming from a DiskSource
        # (in case it isn't this is an error) so the "scanIds" that
        # are passed into us are really tuples, "(scan number, scan name)"
        (scanNum, scanName) = scan.scanId

        startByte = CTRL.startByte()
        endByte   = CTRL.endByte()

        # Attempt to set the correct scan and verify it did set.
        CTRL.send_query("scan_set={0:d}".format(scanNum), [0])
        reply = CTRL.send_query("scan_set?", [0])
        if hasattr(scan, 'duplicate'):
            suffix = uniqSuffix(scanNum)
            if scanName.endswith(suffix):
                # Ok, modify scan name
                # Find the right-most uniqSuffix(). Suppose that by chance
                # the scan with name "name.scan.2" would end up in scan
                # postions #1 and  #2 (duplicated) on the disk pack.
                # then the 2nd uniquefied scan name would be:
                #    "name.scan.2.scan.2"
                # if we then do string.sub(".scan.2", "") it would replace 
                # *both* instances instead of only the last one
                # making our test for the scan's existence on the disk pack
                # fail!
                sidx = scanName.rfind(suffix)
                if sidx<0:
                    raise RuntimeError, "Could not find unique suffix whilst it should be there?!"
                scanName = scanName[0:sidx]
            else:
                raise RuntimeError, \
                        "Scan #{0} ({1}) was marked as duplicate but does not end with expected suffix '{2}'".format( \
                            scanNum, scanName, suffix)
        if not (int(reply[2])==scanNum and reply[3]==scanName):
            raise RuntimeError, "Scan #{0} ({1}) is not that anymore, it is now #{2} ({3})".format( \
                                 scanNum, scanName, int(reply[2]), reply[3])

        # Attempt to connect to remote side
        CTRL.send_query("disk2net=connect:{0:s}".format(dataip), [0])

        # And let it flow!
        CTRL.send_query("disk2net=on:{0}:{1}".format(startByte if startByte else "", endByte if endByte else ""), [0])

    def progress(self):
        r = self.DataSource.send_query("disk2net?")
        return None if r[2]=="inactive" else (int(r[5]), int(r[4]), int(r[6]))

    def cancel(self):
        self.DataSource.send_query("disk2net=disconnect", Mark5.anyReturn)


class file2net(SourceXFER):
    def __init__(self, datasource):
        super(file2net, self).__init__( datasource )

    def start(self, scan, dataip):
        # shorthand to the control interface
        CTRL = self.DataSource

        startByte = CTRL.startByte()
        endByte   = CTRL.endByte()

        CTRL.send_query("file2net=connect:{0:s}:{1:s}".format(dataip, scan.name()), [0])
        CTRL.send_query("file2net=on:{0}:{1}".format(startByte if startByte else "", endByte if endByte else "", [0]))

    def progress(self):
        r = self.DataSource.send_query("file2net?")
        return None if r[2]=="inactive" else (int(r[5]), int(r[4]), int(r[6]))

    def cancel(self):
        self.DataSource.send_query("file2net=disconnect", Mark5.anyReturn)

class vbs2net(SourceXFER):
    def __init__(self, datasource):
        super(vbs2net, self).__init__( datasource )
        # when configuring the number of readers/writers we make some
        # assumptions:
        #   * reading vbs disks is faster than writing (thus nDiskReader <
        #     nDiskWriter)
        # NOTE: 'nthread' is a global parameter, settable from the command
        #       line
        self.DataSource.send_query("vbs2net=nthread:{0}:{1}".format(nthread+1, nthread))

    def start(self, scan, dataip):
        self.DataSource.send_query("vbs2net=connect:{0}:{1}".format(scan.name(), dataip), [0])

    def progress(self):
        r = self.DataSource.send_query("tstat=")
        # we don't know the length of the vbs recording (yet) so let's put
        # in something such that it's always ~98%
        if r[3]!="vbs2net":
            return None
        c = int(r[5])
        return (c, 0, c + max(1, int(float(c)*0.02)))

    def cancel(self):
        self.DataSource.send_query("vbs2net=disconnect", Mark5.anyReturn)


class net2disk(DestXFER):
    def __init__(self, datasink):
        super(net2disk, self).__init__( datasink )

    def open(self, output):
        self.DataSink.send_query("net2disk=open:{0:s}".format(output), [0])

    def cancel(self):
        self.DataSink.send_query("net2disk=close", Mark5.anyReturn)

    def rcv_bytecount(self):
        # net2disk?  replies with:
        # net2disk? 0 : <status> : <scan nr> : <scan name> : <bytes>
        # 0         1   2          3           4             5
        r = self.DataSink.send_query("net2disk?", [0])
        return 0 if (r[2]=="inactive" or len(r)<6) else int(r[5])

class net2file(DestXFER):
    def __init__(self, datasink):
        super(net2file, self).__init__( datasink )

    def open(self, output):
        self.DataSink.send_query("net2file=open:{0:s},{1}".format(output, 'w' if output=="/dev/null" else 'n'), [0])

    def rcv_bytecount(self):
        r = self.DataSink.send_query("net2file?")
        # this will currently fail, have to look into jive5ab code
        return 0 if r[2]=="inactive" else int(r[6])

    def cancel(self):
        self.DataSink.send_query("net2file=close", Mark5.anyReturn)
        

class vbs_record(DestXFER):
    def __init__(self, datasink):
        super(vbs_record, self).__init__( datasink )

        # at the recorder, configure >1 disk writers
        self.DataSink.send_query("record=nthread:1:4", [0])

        # Also configure a different blocksize - the vbs file size
        self.DataSink.send_query("net_protocol=::256M:8")

    def open(self, output):
        # start a recording on the FlexBuff
        # apparently we do need a non-empty mode for that
        self.DataSink.send_query("mode=ext:0xffffffff", [0])
        self.DataSink.send_query("record=on:{0:s}".format(output), [0])

    def rcv_bytecount(self):
        return 0

    def cancel(self):
        self.DataSink.send_query("record=off", Mark5.anyReturn)
        self.DataSink.send_query("mode=none", [0])


class net2vbs(DestXFER):
    def __init__(self, datasink):
        super(net2vbs, self).__init__( datasink )

        # when configuring the number of readers/writers we make some
        # assumptions:
        #   * reading vbs disks is faster than writing (thus nDiskReader <
        #     nDiskWriter)
        #   * the number of netwriters == netreaders so they'll be a nice 
        #     balanced match
        # configure number of netreaders + diskwriters at the receiving end
        # NOTE: 'nthread' is a global parameter which is settable from the
        #       command line
        self.DataSink.send_query("net2vbs=nthread:{0}:{1}".format(nthread, max(nthread+1, 8)), [0])

    def open(self, output):
        # We ignore the output name because the "sync" method will send the
        # file name in each synchronization transfer
        self.DataSink.send_query("net2vbs=open", [0])

    def rcv_bytecount(self):
        return 0

    def cancel(self):
        self.DataSink.send_query("net2vbs=close", Mark5.anyReturn, timeout=10)


############################################################################
##
##  All possible transfer end points have been defined, now we patch
##  them up together to form the supported transfers
##
############################################################################


##### lcl transfers only allowed if media are different
def lcl_xfer(src, dst):
    if src.mediaType==dst.mediaType or \
       src.mediaType==media_type.VBS or \
       dst.mediaType==media_type.VBS:
        raise ValueError, "Unsupported local transfer {0} -> {1}".format(src.mediaType,\
                                                                         dst.mediaType)
    matrix = {
        (media_type.DISK, media_type.FILE): (disk2file, DiskSource, disk2file, FileDest),
        (media_type.FILE, media_type.DISK): (file2disk, FileSource, file2disk, DiskDest)
    }
    return matrix[ (src.mediaType, dst.mediaType) ]

#### The remote transfers: *2net + net2*
# here the media may be identical
def remote_xfer(src, dst):
    matrix = {
        (media_type.DISK, media_type.DISK): (disk2net, DiskSource, net2disk,   DiskDest),
        (media_type.DISK, media_type.FILE): (disk2net, DiskSource, net2file,   FileDest),
        (media_type.FILE, media_type.DISK): (file2net, FileSource, net2disk,   DiskDest),
        (media_type.FILE, media_type.FILE): (file2net, FileSource, net2file,   FileDest),
        (media_type.FILE, media_type.VBS):  (file2net, FileSource, vbs_record, VBSDest),
        (media_type.DISK, media_type.VBS):  (disk2net, DiskSource, vbs_record, VBSDest),
        (media_type.VBS,  media_type.VBS):  (vbs2net,  VBSSource,  net2vbs,    VBSDest),
    }
    return matrix[ (src.mediaType, dst.mediaType) ]

# One entry point which decides if it's a local or a remote transfer
# Will return a quad-tuple with type constructors:
#    (src_xfer_type, src_type, dst_xfer_type, dst_type)
#
# The calling code can construct the DataSource and DataSink from
# the 'src_type' and 'dst_type'. Then loop over all the entries
# in the DataSource and transfer them to the DataSink, using
# the transfer types to set up the source, destination end points
def xfer_selector(src, dst):
    # we have a matrix of endpoints (disk->file, file->disk, etc)
    # and the source/destination ip addresses; now we 
    # decide which transfers to choose
    #  (e.g. "disk(local) -> file(local) => disk2file"
    #        "disk(X)     -> file(Y)     => disk2net + net2file"
    matrix = {
            True:  lcl_xfer,
            False: remote_xfer \
        }
    return matrix[ (src.controlIP == dst.controlIP and \
                    src.controlPort == dst.controlPort) ](src, dst)


## context manager for the transfer type
class actual_xfer(object):
    def __init__(self, sx, dx):
        self.sourceXFER = sx
        self.destXFER   = dx

    def __enter__(self):
        return self

    def __exit__(self, type, value, traceback):
        self.sourceXFER.cancel()
        self.destXFER.cancel()

def attr(obj):
    import inspect
    return filter(lambda x: x[0][0]!='_', inspect.getmembers(obj, lambda x: not inspect.ismethod(x)))

## context manager for a transfer - this means we have 
## the option of doing a clean shutdown
class xfer_context:
    def __init__(self, src, dst):
        self.srcLocation = src
        self.dstLocation = dst
        # Upon construction get the 4 types of the objects we'll need for
        # the transfer
        (self.sxtype, self.stype, self.dxtype, self.dtype) = xfer_selector(self.srcLocation, self.dstLocation)

    def __enter__(self):
        # Upon entering the context, we create the DataSource and DataSink objects
        self.dataSource = self.stype(self.srcLocation)
        self.dataSink   = self.dtype(self.dstLocation)
        # Check if this will work
        if len(self.dataSource)>1 and not self.dataSink.multiple_outputs():
            raise RuntimeError, "Source specifies >1 scan but destination is explicitly set"
        return self

    def __exit__(self, tp, val, tb):
        self.dataSource.cleanup()
        self.dataSink.cleanup()
        if not (type is None and value is None and traceback is None):
            if queries:
                print traceback.print_exception(tp, val, tb)
            else:
                print val
        return True

    def __call__(self):
        # Ok, we're requested to actually do the transfers
        dataSource = self.dataSource
        dataSink   = self.dataSink
        with actual_xfer(self.sxtype(dataSource), self.dxtype(dataSink)) as xfer:
            sxfer = xfer.sourceXFER
            dxfer = xfer.destXFER

            for scan in dataSource:
                outname = dataSink.compute_outputname(scan)
                print dataSource.location()+scan.name(), "=>", dataSink.location()+outname
                dxfer.open(outname)
                sxfer.start(scan, dataSink.dataIP())

                progress = Progress(45) if verbose else DummyProgress()
                while True:
                    p = sxfer.progress()
                    if not p:
                        break
                    progress(*p)
                    time.sleep(1)
                oldbytes = dxfer.rcv_bytecount()
                progress.say("Waiting for remote end to flush ... "+str(oldbytes))
                while True:
                    time.sleep(1)
                    newbytes = dxfer.rcv_bytecount()
                    if newbytes==oldbytes:
                        break
                    oldbytes = newbytes
                    progress.say("Waiting for remote end to flush ... "+str(oldbytes))
                sxfer.cancel()
                dxfer.cancel()
                progress.done()


class catcher(object):
    def __init__(self):
        pass

    def __enter__(self):
        return self

    def __exit__(self, tp, val, tb):
        if not (type is None and value is None and traceback is None):
            if queries:
                print traceback.print_exception(tp, val, tb)
            else:
                print val
        return True

# returns None if the argument wasn't present, tp(<value>) if it was
# (such that it will give an exception if e.g. you expect int but
#  the user didn't pass a valid int
def get_val(arg, tp=str):
    conversion_error = False
    try:
        # is 'arg' given?
        aidx = sys.argv.index(arg)  # raises ValueError if not found FFS
        aval = sys.argv[aidx+1]     # raises IndexError

        # Check it doesn't start with a '-'!
        if aval[0]=='-':
            raise RuntimeError, "Option %s expects argument, got another option '%s'" % (arg, aval)

        # remove those arguments
        del sys.argv[aidx]; del sys.argv[aidx]
        # now set 'conversion_error' to True because the following
        # statement could (also) raise a ValueError (like the
        # "sys.argv.index()"). FFS Python! So we must take measures to tell
        # them apart
        conversion_error = True
        return tp(aval)
    except ValueError:
        if conversion_error:
            raise
        # no 'arg' given, don't complain
        return None
    except IndexError:
        # Mission option value to option
        raise RuntimeError, "Mission optionvalue to {0}".format(arg)



##################
# the main program
##################

if __name__ == "__main__":
    #########################
    ## Check command line
    #########################

    # Was '-h' requested?
    if len(sys.argv)==1 or '-h' in sys.argv:
        usage()
        sys.exit( 0 )

    # Or maybe '-v' (version)
    if '-v' in sys.argv:
        print version
        sys.exit( 0 )

    # before actually starting to process the args ... we must find the "-p
    # <port>" and extract it manually (the alternative would be to say
    # "p=<port>" but that's a bit ugly and looks too much like dd(1).
    p = get_val('-p', int)
    if p:
        dataport = p
    m = get_val('-m', int)
    if m:
        if m<64:
            raise RuntimeError, "Value '{0}' for MTU is lower than ethernet minimum of 64".format(m)
        if m<1500:
            print "WARN: mtu set to value <1500. Probably negative impact on transfer speed"
        mtu = m
    n = get_val('-n', int)
    if n:
        if n<=1:
            raise RuntimeError, "Illegal number of parallel file transfers: {0}".format(n)
        nthread = n
    # Check if a rate was given
    rate = get_val('-r')
    if rate:
        # convert rate to bits per second
        rate = float(procByte(rate, float, rxBytenumRate, scaleTableMetric))
        if rate==0:
            raise RuntimeError, "Data rate 0 (zero) is not supported"
        # ipd in nano seconds = (mtu*8 / rate) * 1.0e9
        ipd = int( (float(mtu)*8 / rate)*1.0e9 )

    # Split remaining commandline in options and arguments
    (opts, args) = partition(lambda x: re.match("^-", x), sys.argv[1:])

    # require two arguments
    if len(args)!=2:
        usage()
        sys.exit( 1 )

    # UDT requested?
    if '-udt' in opts:
        protocol="udt"

    if '-q' in opts:
        verbose=False

    if '-a' in opts:
        duplicates=True

    # hidden option '-d' - turn on debugging
    if '-d' in opts:
        queries=True

    if verbose:
        print """%s
    copy VLBI data from somewhere to elsewhere
               (c) H. Verkouter
""" % version

    # Note: we've already checked that there's exactly two arguments!
    src = parseURI(args[0], uri_type.SRC)
    dst = parseURI(args[1], uri_type.DST)

    if verbose:
        print src," ===> ",dst
   
    with catcher() as c:
        with xfer_context(src, dst) as xfer:
            xfer()
